from __future__ import annotations

import argparse
import json
import os
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

# .env íŒŒì¼ ìë™ ë¡œë“œ
try:
    from dotenv import load_dotenv
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ ë¡œë“œ
    env_path = Path(__file__).resolve().parent.parent.parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)
except ImportError:
    # python-dotenvê°€ ì—†ìœ¼ë©´ ìˆ˜ë™ìœ¼ë¡œ ë¡œë“œ ì‹œë„
    env_path = Path(__file__).resolve().parent.parent.parent / ".env"
    if env_path.exists():
        with open(env_path) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ.setdefault(key.strip(), value.strip())

from gap_foundry.crew import Step1CrewFactory
from gap_foundry.input_refiner import refine_inputs


REQUIRED_KEYS = [
    "idea_one_liner",
    "target_customer",
    "problem_statement",
    "current_alternatives",
    "geo_market",
    "business_type",
]

# ì„ íƒì  í•„ë“œ (ê¸°ë³¸ê°’ ì œê³µ)
OPTIONAL_FIELDS = {
    "constraints": "íŠ¹ë³„í•œ ì œì•½ ì—†ìŒ",
    "success_definition": "ê²½ìŸì‚¬ ëŒ€ë¹„ ëª…í™•í•œ ì°¨ë³„ì  ë„ì¶œ",
}


def _load_inputs_from_json(path: Path) -> Dict[str, Any]:
    if not path.exists():
        raise FileNotFoundError(f"Input JSON not found: {path}")
    with path.open("r", encoding="utf-8") as f:
        data = json.load(f)
    if not isinstance(data, dict):
        raise ValueError("Input JSON must be an object/dict.")
    return data


def _prompt_missing_fields(data: Dict[str, Any]) -> Dict[str, Any]:
    for k in REQUIRED_KEYS:
        if not data.get(k):
            data[k] = input(f"{k}: ").strip()
    return data


def _validate_inputs(data: Dict[str, Any]) -> None:
    missing = [k for k in REQUIRED_KEYS if not data.get(k)]
    if missing:
        raise ValueError(f"Missing required input keys: {missing}")


# ============================================================================
# ìš´ì˜ê¸‰ ê°€ë“œë ˆì¼ #2: ê²½ìŸì‚¬ ìˆ˜ í›„ì²˜ë¦¬ ê°•ì œ ì»·
# ============================================================================

MAX_COMPETITORS_ITEMS = 8  # items ìµœëŒ€ 8ê°œ
MAX_COMPETITORS_CANDIDATES = 15  # candidates ìµœëŒ€ 15ê°œ


def _compact_competitors_output(raw_output: str) -> Tuple[str, bool]:
    """
    discover_competitors ì¶œë ¥ì„ íŒŒì‹±í•´ì„œ ê°•ì œ ì»·í•œë‹¤.
    
    Returns:
        (compacted_output, was_truncated)
    """
    # JSON ì¶”ì¶œ ì‹œë„
    json_match = re.search(r"```json\s*([\s\S]*?)\s*```", raw_output, re.IGNORECASE)
    if not json_match:
        # JSON ë¸”ë¡ì´ ì—†ìœ¼ë©´ { ... } ì°¾ê¸°
        first = raw_output.find("{")
        last = raw_output.rfind("}")
        if 0 <= first < last:
            json_str = raw_output[first:last + 1]
        else:
            return raw_output, False
    else:
        json_str = json_match.group(1)
    
    try:
        data = json.loads(json_str)
    except json.JSONDecodeError:
        return raw_output, False
    
    was_truncated = False
    
    # items ê°•ì œ ì»·
    if "items" in data and isinstance(data["items"], list):
        if len(data["items"]) > MAX_COMPETITORS_ITEMS:
            data["items"] = data["items"][:MAX_COMPETITORS_ITEMS]
            was_truncated = True
    
    # candidates ê°•ì œ ì»·
    if "candidates" in data and isinstance(data["candidates"], list):
        if len(data["candidates"]) > MAX_COMPETITORS_CANDIDATES:
            data["candidates"] = data["candidates"][:MAX_COMPETITORS_CANDIDATES]
            was_truncated = True
    
    # notes í•„ë“œ ì œê±° (ë¶ˆí•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ ê°ì†Œ)
    for item in data.get("items", []):
        if isinstance(item, dict) and "notes" in item:
            # notesë¥¼ 1ì¤„ë¡œ ì¶•ì•½
            notes = item.get("notes", "")
            if isinstance(notes, str) and len(notes) > 50:
                item["notes"] = notes[:50] + "..."
    
    compacted = "```json\n" + json.dumps(data, ensure_ascii=False, indent=2) + "\n```"
    return compacted, was_truncated


# ============================================================================
# ìš´ì˜ê¸‰ ê°€ë“œë ˆì¼ #5: Preflight ì•ˆì „ ì ê²€
# ============================================================================

CONTEXT_SIZE_THRESHOLD = 15000  # 15k ë¬¸ì ë„˜ìœ¼ë©´ ìœ„í—˜


def _preflight_check(crew, safe_mode: bool = False) -> Dict[str, Any]:
    """
    ì‹¤í–‰ ì „ context í¬ê¸°ë¥¼ ì²´í¬í•˜ê³ , ìœ„í—˜í•˜ë©´ ê²½ê³ /ìë™ ì¶•ì†Œ.
    
    Returns:
        {
            "total_chars": int,
            "is_safe": bool,
            "warnings": list[str],
            "auto_adjusted": bool,
        }
    """
    result = {
        "total_chars": 0,
        "is_safe": True,
        "warnings": [],
        "auto_adjusted": False,
    }
    
    # ì´ë¯¸ ì‹¤í–‰ëœ íƒœìŠ¤í¬ ê²°ê³¼ë“¤ì˜ í¬ê¸° í•©ì‚°
    tasks = getattr(crew, "tasks", [])
    for task in tasks:
        output = getattr(task, "output", None)
        if output:
            raw = getattr(output, "raw", "") or ""
            result["total_chars"] += len(raw)
    
    # ì„ê³„ì¹˜ ì²´í¬
    if result["total_chars"] > CONTEXT_SIZE_THRESHOLD:
        result["is_safe"] = False
        result["warnings"].append(
            f"âš ï¸ í˜„ì¬ context í¬ê¸°: {result['total_chars']:,}ì (ì„ê³„ì¹˜: {CONTEXT_SIZE_THRESHOLD:,}ì)"
        )
        
        if safe_mode:
            # safe_modeì—ì„œëŠ” ìë™ ì¶•ì†Œ í”Œë˜ê·¸ë§Œ ì„¤ì • (ì‹¤ì œ ì¶•ì†ŒëŠ” callerê°€ ì²˜ë¦¬)
            result["auto_adjusted"] = True
            result["warnings"].append("ğŸ”§ Safe Mode: ìë™ ì¶•ì†Œ ì ìš©ë¨")
    
    return result


def _print_preflight_warnings(preflight_result: Dict[str, Any]) -> None:
    """Preflight ê²½ê³  ì¶œë ¥"""
    if preflight_result["warnings"]:
        print("\n" + "â”€" * 60)
        print("ğŸ” Preflight ì ê²€ ê²°ê³¼")
        for w in preflight_result["warnings"]:
            print(f"   {w}")
        print("â”€" * 60 + "\n")


def _safe_write_text(path: Path, content: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")


def _log_usage_metrics(
    crew, 
    out_dir: Path, 
    run_id: str, 
    elapsed_seconds: Optional[float] = None
) -> Dict[str, Any]:
    """
    CrewAIì˜ usage_metricsë¥¼ ì¶”ì¶œí•˜ì—¬ ë¡œê¹…í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.
    
    CrewAIëŠ” crew.usage_metricsì—ì„œ í† í° ì‚¬ìš©ëŸ‰ì„ ì œê³µí•œë‹¤.
    https://docs.crewai.com/concepts/crews#crew-usage-metrics
    
    Args:
        crew: CrewAI Crew ê°ì²´
        out_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        run_id: ì‹¤í–‰ ID
        elapsed_seconds: ì‹¤í–‰ ì‹œê°„ (ì´ˆ)
    """
    metrics: Dict[str, Any] = {
        "run_id": run_id,
        "timestamp": datetime.now().isoformat(),
        "tokens": {},
        "estimated_cost_usd": None,
        "elapsed_seconds": elapsed_seconds,
        "elapsed_formatted": None,
    }
    
    # ì‹¤í–‰ ì‹œê°„ í¬ë§·íŒ…
    if elapsed_seconds is not None:
        minutes, seconds = divmod(int(elapsed_seconds), 60)
        if minutes > 0:
            metrics["elapsed_formatted"] = f"{minutes}ë¶„ {seconds}ì´ˆ"
        else:
            metrics["elapsed_formatted"] = f"{seconds}ì´ˆ"

    # CrewAI usage_metrics ì¶”ì¶œ
    usage = getattr(crew, "usage_metrics", None)
    if usage:
        # CrewAIì˜ usage_metrics êµ¬ì¡°ì— ë§ê²Œ ì¶”ì¶œ
        if isinstance(usage, dict):
            metrics["tokens"] = usage
        else:
            # UsageMetrics ê°ì²´ì¸ ê²½ìš°
            metrics["tokens"] = {
                "total_tokens": getattr(usage, "total_tokens", 0),
                "prompt_tokens": getattr(usage, "prompt_tokens", 0),
                "completion_tokens": getattr(usage, "completion_tokens", 0),
                "successful_requests": getattr(usage, "successful_requests", 0),
            }

    # ë¹„ìš© ì¶”ì • (ëŒ€ëµì ì¸ OpenAI ê°€ê²© ê¸°ì¤€)
    # GPT-4o: $2.50/1M input, $10/1M output
    # GPT-4o-mini: $0.15/1M input, $0.60/1M output
    # ì—¬ê¸°ì„œëŠ” í‰ê· ìœ¼ë¡œ ëŒ€ëµ ì¶”ì •
    total_tokens = metrics["tokens"].get("total_tokens", 0)
    if total_tokens > 0:
        # í˜¼í•© ì‚¬ìš© ê°€ì •: í‰ê·  $1.50/1M tokens (ë³´ìˆ˜ì  ì¶”ì •)
        metrics["estimated_cost_usd"] = round(total_tokens * 1.5 / 1_000_000, 4)

    # ì½˜ì†” ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“Š ì‹¤í–‰ í†µê³„ (Usage Metrics)")
    print("=" * 60)
    
    # ì‹œê°„ ë¨¼ì € í‘œì‹œ
    if metrics["elapsed_formatted"]:
        print(f"   â±ï¸  ì‹¤í–‰ ì‹œê°„: {metrics['elapsed_formatted']}")
    
    if metrics["tokens"]:
        for k, v in metrics["tokens"].items():
            print(f"   {k}: {v:,}" if isinstance(v, int) else f"   {k}: {v}")
    if metrics["estimated_cost_usd"]:
        print(f"   ğŸ’° ì¶”ì • ë¹„ìš©: ${metrics['estimated_cost_usd']:.4f} USD")
    else:
        print("   ğŸ’° ì¶”ì • ë¹„ìš©: (ë°ì´í„° ì—†ìŒ)")

    # íŒŒì¼ ì €ì¥
    metrics_path = out_dir / "runs" / run_id / "_usage_metrics.json"
    _safe_write_text(metrics_path, json.dumps(metrics, ensure_ascii=False, indent=2))
    print(f"   ğŸ“ ì €ì¥ë¨: {metrics_path}")

    return metrics


# ============================================================================
# íŒŒì¼ëª… ë§¤í•‘ (ì˜ë¯¸ ìˆëŠ” ì§§ì€ ì´ë¦„)
# ============================================================================

TASK_FILENAME_MAP = {
    "discover_competitors": "01_ê²½ìŸì‚¬_ë°œêµ´",
    "compact_competitors": "02_ê²½ìŸì‚¬_ì••ì¶•",
    "analyze_channels": "03_ì±„ë„_ë¶„ì„",
    "extract_value_props": "04_ê°€ì¹˜ì œì•ˆ_ì¶”ì¶œ",
    "summarize_channels_vp": "05_ì±„ë„VP_ìš”ì•½",
    "mine_gaps": "06_ë¹ˆí‹ˆ_ë°œêµ´",
    "summarize_research": "07_ë¦¬ì„œì¹˜_ìš”ì•½",
    "create_pov_and_positioning": "08_POV_í¬ì§€ì…”ë‹",
    "red_team_review": "09_ë ˆë“œíŒ€_ê²€í† ",
    "revise_positioning": "10_í¬ì§€ì…”ë‹_ìˆ˜ì •",
    "red_team_recheck": "11_ë ˆë“œíŒ€_ì¬ê²€í† ",
    "final_step1_report": "12_ìµœì¢…_ë¦¬í¬íŠ¸",
}

TASK_EMOJI_MAP = {
    "discover_competitors": "ğŸ”",
    "compact_competitors": "ğŸ“¦",
    "analyze_channels": "ğŸ“¢",
    "extract_value_props": "ğŸ’",
    "summarize_channels_vp": "ğŸ“‹",
    "mine_gaps": "ğŸ•³ï¸",
    "summarize_research": "ğŸ“‘",
    "create_pov_and_positioning": "ğŸ¯",
    "red_team_review": "ğŸ”´",
    "revise_positioning": "âœï¸",
    "red_team_recheck": "ğŸ”´",
    "final_step1_report": "ğŸ“Š",
}


def _generate_run_id(inputs: Dict[str, Any]) -> str:
    """
    ì˜ë¯¸ ìˆëŠ” run_id ìƒì„±
    í˜•ì‹: YYYY-MM-DD_ì•„ì´ë””ì–´ìš”ì•½_íƒ€ì…
    ì˜ˆ: 2026-01-16_AIì´ë ¥ì„œìë™ì‘ì„±_B2C
    """
    date_str = datetime.now().strftime("%Y-%m-%d_%H%M")
    
    # ì•„ì´ë””ì–´ì—ì„œ í•µì‹¬ ë‹¨ì–´ ì¶”ì¶œ (í•œê¸€/ì˜ë¬¸, ìµœëŒ€ 15ì)
    idea = inputs.get("idea_one_liner", "unknown")
    # ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  í•µì‹¬ë§Œ
    idea_clean = re.sub(r"[^\wê°€-í£]", "", idea)[:15]
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ íƒ€ì…
    biz_type = inputs.get("business_type", "")
    
    # ì¡°í•©
    run_id = f"{date_str}_{idea_clean}"
    if biz_type:
        run_id += f"_{biz_type}"
    
    # íŒŒì¼ì‹œìŠ¤í…œ ì•ˆì „í•˜ê²Œ
    run_id = re.sub(r"[/\\:*?\"<>|]", "_", run_id)
    
    return run_id


def _extract_task_id(task) -> str:
    """
    Task ê°ì²´ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‹ë³„ìë¥¼ ë½‘ê¸° ìœ„í•œ í—¬í¼.
    CrewAI ë²„ì „ì— ë”°ë¼ name/idê°€ ì—†ì„ ìˆ˜ ìˆì–´ description ì²« ì¤„ë¡œ ëŒ€ì²´.
    """
    # ìš°ì„ ìˆœìœ„: name -> id -> description prefix
    name = getattr(task, "name", None)
    if isinstance(name, str) and name.strip():
        return name.strip()

    tid = getattr(task, "id", None)
    if isinstance(tid, str) and tid.strip():
        return tid.strip()

    desc = getattr(task, "description", "") or ""
    first = desc.strip().splitlines()[0] if desc.strip() else "task"
    first = first[:40].strip().replace(" ", "_")
    return first or "task"


def _get_friendly_filename(task_id: str, index: int) -> str:
    """íƒœìŠ¤í¬ IDë¥¼ ì˜ë¯¸ ìˆëŠ” íŒŒì¼ëª…ìœ¼ë¡œ ë³€í™˜"""
    # ë§¤í•‘ì—ì„œ ì°¾ê¸°
    if task_id in TASK_FILENAME_MAP:
        return TASK_FILENAME_MAP[task_id]
    
    # ë§¤í•‘ì— ì—†ìœ¼ë©´ ê¸°ë³¸ í˜•íƒœ
    return f"{index:02d}_{task_id[:30]}"


def _generate_task_header(task_id: str, run_id: str) -> str:
    """íƒœìŠ¤í¬ë³„ í—¤ë” ìƒì„±"""
    emoji = TASK_EMOJI_MAP.get(task_id, "ğŸ“„")
    friendly_name = TASK_FILENAME_MAP.get(task_id, task_id).replace("_", " ").split("_", 1)[-1] if "_" in TASK_FILENAME_MAP.get(task_id, "") else task_id
    
    header = f"""<!--
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {emoji} Gap Foundry - {friendly_name}
â”‚ Run ID: {run_id}
â”‚ Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
-->

"""
    return header


def _generate_report_header(inputs: Dict[str, Any], run_id: str, args) -> str:
    """ìµœì¢… ë¦¬í¬íŠ¸ ë©”íƒ€ ì •ë³´ í—¤ë” ìƒì„±"""
    idea = inputs.get("idea_one_liner", "N/A")[:60]
    target = inputs.get("target_customer", "N/A")[:40]
    geo = inputs.get("geo_market", "N/A")
    biz_type = inputs.get("business_type", "N/A")
    
    mode = "Safe Mode" if getattr(args, "safe_mode", False) else "Standard"
    if getattr(args, "auto_revise", False):
        mode += " + Auto-Revise"
    
    header = f"""<!--
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        ğŸ¯ GAP FOUNDRY - STEP1 REPORT                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ“Œ Idea: {idea:<62} â•‘
â•‘  ğŸ‘¥ Target: {target:<60} â•‘
â•‘  ğŸŒ Market: {geo:<10}  |  ğŸ’¼ Type: {biz_type:<8}  |  âš™ï¸ Mode: {mode:<15} â•‘
â•‘  ğŸ• Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S"):<25}  |  ğŸ”– Run ID: {run_id:<12} â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-->

"""
    return header


def _save_task_outputs(
    crew,
    out_dir: Path,
    run_id: str,
    also_save_json_when_possible: bool = True,
) -> Dict[str, str]:
    """
    crew.kickoff() í›„ crew.tasksë¥¼ ìˆœíšŒí•˜ë©´ì„œ ê° task.outputì„ ì €ì¥.
    TaskOutputì€ task.output.raw / task.output.json_dict ë“±ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥.
    """
    outputs_dir = out_dir / "runs" / run_id
    outputs_dir.mkdir(parents=True, exist_ok=True)

    index: Dict[str, str] = {}

    for i, task in enumerate(getattr(crew, "tasks", []) or []):
        task_id = _extract_task_id(task)
        
        # ì˜ë¯¸ ìˆëŠ” íŒŒì¼ëª… ìƒì„±
        file_stem = _get_friendly_filename(task_id, i + 1)
        raw_path = outputs_dir / f"{file_stem}.md"

        task_output = getattr(task, "output", None)
        if task_output is None:
            _safe_write_text(raw_path, "# (No output)\n")
            index[task_id] = str(raw_path)
            continue

        raw = getattr(task_output, "raw", "") or ""
        
        # ìµœì¢… ë¦¬í¬íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° í—¤ë” ì¶”ê°€
        if task_id != "final_step1_report":
            header = _generate_task_header(task_id, run_id)
            raw = header + raw
        
        _safe_write_text(raw_path, raw)
        index[task_id] = str(raw_path)

        # ê°€ëŠ¥í•˜ë©´ JSONë„ ì €ì¥
        if also_save_json_when_possible:
            json_dict = getattr(task_output, "json_dict", None)
            if isinstance(json_dict, dict):
                json_path = outputs_dir / f"{file_stem}.json"
                _safe_write_text(json_path, json.dumps(json_dict, ensure_ascii=False, indent=2))
                index[task_id + "_json"] = str(json_path)

    # ì¸ë±ìŠ¤ íŒŒì¼ ì €ì¥
    index_path = outputs_dir / "_index.json"
    _safe_write_text(index_path, json.dumps(index, ensure_ascii=False, indent=2))

    return index


def _parse_verdict_from_text(text: str) -> Optional[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ VERDICTë¥¼ íŒŒì‹±í•œë‹¤."""
    if not text:
        return None
    
    # VERDICT: PASS ë˜ëŠ” VERDICT: FAIL íŒ¨í„´ ì°¾ê¸°
    # ë³€í˜• ëŒ€ì‘: "VERDICT:FAIL", "VERDICT : PASS", "VERDICT: PASS âœ…" ë“±
    match = re.search(r"VERDICT\s*:\s*(PASS|FAIL)", text, re.IGNORECASE)
    if match:
        return match.group(1).upper()
    
    # **VERDICT: FAIL** íŒ¨í„´ (ë§ˆí¬ë‹¤ìš´ bold)
    match_bold = re.search(r"\*\*VERDICT\s*:\s*(PASS|FAIL)\*\*", text, re.IGNORECASE)
    if match_bold:
        return match_bold.group(1).upper()
    
    return None


def _extract_verdict_from_crew(crew, out_dir: Optional[Path] = None, run_id: Optional[str] = None) -> Tuple[str, str]:
    """
    Crew ì‹¤í–‰ í›„ red_team_review ë˜ëŠ” red_team_recheck íƒœìŠ¤í¬ì—ì„œ VERDICTë¥¼ ì¶”ì¶œí•œë‹¤.
    
    Args:
        crew: CrewAI Crew ê°ì²´
        out_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (íŒŒì¼ì—ì„œ fallback ì½ê¸°ìš©)
        run_id: ì‹¤í–‰ ID (íŒŒì¼ì—ì„œ fallback ì½ê¸°ìš©)
    
    Returns:
        (verdict, raw_output)
        - verdict: "PASS" | "FAIL" | "UNKNOWN"
        - raw_output: red_team íƒœìŠ¤í¬ì˜ ì „ì²´ ì¶œë ¥
    """
    # red_team íƒœìŠ¤í¬ ì°¾ê¸° - ë‹¤ì¤‘ ë°©ì‹ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ
    red_team_tasks = []
    for task in getattr(crew, "tasks", []) or []:
        # 1) agent roleë¡œ ì°¾ê¸° (ê°€ì¥ ì•ˆì „)
        agent = getattr(task, "agent", None)
        agent_role = (getattr(agent, "role", "") or "").lower()
        if "red_team" in agent_role or "ë ˆë“œíŒ€" in agent_role or "ë°˜ì¦" in agent_role:
            red_team_tasks.append(task)
            continue
        
        # 2) description ì „ì²´ì—ì„œ ì°¾ê¸° (fallback)
        desc = (getattr(task, "description", "") or "").lower()
        if "red_team" in desc or "ê³µê²©ì ìœ¼ë¡œ ê²€í† " in desc or "verdict" in desc:
            red_team_tasks.append(task)
            continue
        
        # 3) task_id íŒ¨í„´ìœ¼ë¡œ ì°¾ê¸° (ë§ˆì§€ë§‰ fallback)
        task_id = _extract_task_id(task)
        if "red_team" in task_id.lower():
            red_team_tasks.append(task)
    
    # === ë°©ë²• 1: task.outputì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° ===
    if red_team_tasks:
        # ë§ˆì§€ë§‰ red_team íƒœìŠ¤í¬ (recheckì´ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©)
        last_red_team = red_team_tasks[-1]
        task_output = getattr(last_red_team, "output", None)
        
        if task_output is not None:
            raw = getattr(task_output, "raw", "") or str(task_output) or ""
            verdict = _parse_verdict_from_text(raw)
            if verdict:
                return verdict, raw
    
    # === ë°©ë²• 2: ì €ì¥ëœ íŒŒì¼ì—ì„œ ì½ê¸° (fallback) ===
    if out_dir and run_id:
        run_dir = out_dir / "runs" / run_id
        if run_dir.exists():
            # ë ˆë“œíŒ€ ê´€ë ¨ íŒŒì¼ ì°¾ê¸° (09_ë ˆë“œíŒ€_ê²€í†  ë˜ëŠ” 11_ë ˆë“œíŒ€_ì¬ê²€í† )
            red_team_files = []
            for f in sorted(run_dir.glob("*.md")):
                fname_lower = f.name.lower()
                if "ë ˆë“œíŒ€" in fname_lower or "red_team" in fname_lower:
                    red_team_files.append(f)
            
            # ë§ˆì§€ë§‰ ë ˆë“œíŒ€ íŒŒì¼ì—ì„œ VERDICT íŒŒì‹±
            if red_team_files:
                last_file = red_team_files[-1]
                try:
                    content = last_file.read_text(encoding="utf-8")
                    verdict = _parse_verdict_from_text(content)
                    if verdict:
                        return verdict, content
                except Exception:
                    pass
    
    # === ë°©ë²• 3: crewì˜ ì „ì²´ ê²°ê³¼ì—ì„œ ì°¾ê¸° ===
    # CrewAIì˜ ê²°ê³¼ ê°ì²´ì—ì„œ ì§ì ‘ ì°¾ê¸°
    crew_result = getattr(crew, "result", None) or getattr(crew, "_result", None)
    if crew_result:
        result_str = str(crew_result)
        verdict = _parse_verdict_from_text(result_str)
        if verdict:
            return verdict, result_str
    
    return "UNKNOWN", ""


def _get_task_output_by_name(crew, task_name_pattern: str) -> str:
    """íŠ¹ì • íƒœìŠ¤í¬ì˜ ì¶œë ¥ì„ ê°€ì ¸ì˜¨ë‹¤."""
    for task in getattr(crew, "tasks", []) or []:
        task_id = _extract_task_id(task)
        if task_name_pattern.lower() in task_id.lower():
            task_output = getattr(task, "output", None)
            if task_output:
                return getattr(task_output, "raw", "") or ""
    return ""


# ============================================================================
# í›„ì† ëŒ€í™” ê¸°ëŠ¥ (ë¦¬í¬íŠ¸ì— ëŒ€í•œ Q&A)
# ============================================================================

def _start_report_chat(report_text: str, inputs: Dict[str, Any]) -> None:
    """
    ë¦¬í¬íŠ¸ ì™„ë£Œ í›„ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ëŠ” ëª¨ë“œ.
    ì‚¬ìš©ìê°€ ë¦¬í¬íŠ¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê±°ë‚˜ ë°˜ë¡ (Claim)ì„ ì œê¸°í•˜ë©´ LLMì´ ë‹µë³€í•œë‹¤.
    """
    try:
        from crewai import LLM
    except ImportError:
        print("âš ï¸ CrewAI LLMì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€í™” ëª¨ë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # LLM ì´ˆê¸°í™” (main ëª¨ë¸ ì‚¬ìš©)
    model = os.getenv("MAIN_LLM_MODEL", "gpt-4.1")
    llm = LLM(model=model)
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    idea = inputs.get("idea_one_liner", "N/A")
    target = inputs.get("target_customer", "N/A")
    
    system_prompt = f"""ë‹¹ì‹ ì€ ì‹œì¥ê²€ì¦ ë¦¬í¬íŠ¸ì— ëŒ€í•´ í† ë¡ í•˜ëŠ” ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

[ì•„ì´ë””ì–´ ë°°ê²½]
- ì•„ì´ë””ì–´: {idea}
- íƒ€ê¹ƒ ê³ ê°: {target}

[ë¦¬í¬íŠ¸ ë‚´ìš©]
{report_text[:8000]}  # í† í° ì œí•œì„ ìœ„í•´ ì•ë¶€ë¶„ë§Œ

[ì—­í• ]
- ì‚¬ìš©ìê°€ ë¦¬í¬íŠ¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´ ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
- ì‚¬ìš©ìê°€ ë°˜ë¡ (Claim)ì„ ì œê¸°í•˜ë©´:
  1. ë¨¼ì € ê·¸ ê´€ì ì„ ì¸ì •í•˜ê³ 
  2. ë¦¬í¬íŠ¸ì˜ ê·¼ê±°ì™€ ë¹„êµ ë¶„ì„í•˜ê³ 
  3. ê°€ëŠ¥í•˜ë‹¤ë©´ ìƒˆë¡œìš´ ì‹œê°ì„ ì œì‹œí•˜ì„¸ìš”.
- ì‚¬ìš©ìì˜ ê´€ì ì´ íƒ€ë‹¹í•˜ë©´ ì¸ì •í•˜ê³ , ë¦¬í¬íŠ¸ ê²°ë¡  ìˆ˜ì •ì„ ì œì•ˆí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
- í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- ë‹µë³€ì€ ê°„ê²°í•˜ê²Œ (3-5ë¬¸ë‹¨ ì´ë‚´).
"""
    
    conversation_history = [{"role": "system", "content": system_prompt}]
    
    print("\n" + "=" * 60)
    print("ğŸ’¬ ë¦¬í¬íŠ¸ í›„ì† ëŒ€í™” ëª¨ë“œ")
    print("=" * 60)
    print("ë¦¬í¬íŠ¸ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ë‚˜ ë°˜ë¡ ì´ ìˆìœ¼ë©´ ììœ ë¡­ê²Œ ë§ì”€í•˜ì„¸ìš”.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit', 'exit', ë˜ëŠ” 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("=" * 60 + "\n")
    
    while True:
        try:
            user_input = input("ğŸ“ ë‚˜: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\n\nëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ‘‹")
            break
        
        if not user_input:
            continue
        
        if user_input.lower() in ["quit", "exit", "q", "ì¢…ë£Œ", "ë", "ë‚˜ê°€ê¸°"]:
            print("\nëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ‘‹")
            break
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        conversation_history.append({"role": "user", "content": user_input})
        
        # LLM í˜¸ì¶œ
        try:
            response = llm.call(messages=conversation_history)
            
            # ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            conversation_history.append({"role": "assistant", "content": response})
            
            print(f"\nğŸ¤– AI: {response}\n")
            
        except Exception as e:
            print(f"\nâš ï¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            print("   ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n")
            # ì‹¤íŒ¨í•œ ë©”ì‹œì§€ëŠ” íˆìŠ¤í† ë¦¬ì—ì„œ ì œê±°
            conversation_history.pop()


def _load_pass1_outputs_for_revision(out_dir: Path, run_id_pass1: str) -> Dict[str, str]:
    """
    Pass1 outputsì—ì„œ revisionì— í•„ìš”í•œ íŒŒì¼ë“¤ì„ ì½ì–´ì˜¨ë‹¤.
    
    Returns:
        Dict with keys: previous_positioning_output, previous_red_team_output, research_summary
    """
    pass1_dir = out_dir / "runs" / run_id_pass1
    
    def read_md(pattern: str) -> str:
        """íŒ¨í„´ì´ í¬í•¨ëœ md íŒŒì¼ ì½ê¸°"""
        for f in pass1_dir.glob("*.md"):
            if pattern.lower() in f.name.lower():
                try:
                    return f.read_text(encoding="utf-8")
                except Exception:
                    continue
        return ""
    
    return {
        "previous_positioning_output": (
            read_md("create_pov") or read_md("positioning") or read_md("pov")
        ),
        "previous_red_team_output": (
            read_md("red_team_review") or read_md("red_team")
        ),
        "research_summary": (
            read_md("summarize") or read_md("summary")
        ),
        "gap_hypotheses": (
            read_md("mine_gaps") or read_md("gap")
        ),
    }


def main(argv: Optional[list[str]] = None) -> int:
    parser = argparse.ArgumentParser(
        description="Gap Foundry - STEP1 (Competitive Analysis + Idea Refinement) runner"
    )

    parser.add_argument(
        "--input",
        type=str,
        default="",
        help="Path to input JSON file. If omitted, uses CLI args or interactive prompts.",
    )
    parser.add_argument("--idea", type=str, default="", help="One-liner idea")
    parser.add_argument("--target", type=str, default="", help="Target customer")
    parser.add_argument("--problem", type=str, default="", help="Problem statement")
    parser.add_argument(
        "--alternatives",
        type=str,
        default="",
        help="Current alternatives (comma-separated or free text; ideally 3+)",
    )
    parser.add_argument("--geo", type=str, default="KR", help="Geo market (KR/Global)")
    parser.add_argument("--type", type=str, default="B2B", help="Business type (B2B/B2C)")
    parser.add_argument("--constraints", type=str, default="", help="Constraints")
    parser.add_argument("--success", type=str, default="", help="Success definition (STEP1)")

    # ìµœì¢… ë¦¬í¬íŠ¸ ì €ì¥ ê²½ë¡œ(ì˜µì…˜)
    parser.add_argument(
        "--out",
        type=str,
        default="",
        help="Optional final report path (e.g. outputs/step1_report.md). If omitted, prints to stdout.",
    )

    # íƒœìŠ¤í¬ë³„ ì‚°ì¶œë¬¼ ì €ì¥ ë””ë ‰í† ë¦¬(ê¸°ë³¸ê°’: outputs)
    parser.add_argument(
        "--out-dir",
        type=str,
        default="outputs",
        help="Directory to save per-task outputs (default: outputs).",
    )

    parser.add_argument(
        "--interactive",
        action="store_true",
        help="Prompt for missing fields interactively.",
    )

    parser.add_argument(
        "--refine",
        type=str,
        nargs="?",
        const="",
        default=None,
        help="LLM ê¸°ë°˜ ì…ë ¥ êµ¬ì²´í™” ëª¨ë“œ. ì•„ì´ë””ì–´ë¥¼ ììœ ë¡­ê²Œ ì„¤ëª…í•˜ë©´ í•„ìš”í•œ ì •ë³´ë¥¼ ìë™ ì¶”ì¶œ/ì§ˆë¬¸. "
             "ì´ˆê¸° ì•„ì´ë””ì–´ë¥¼ ì¸ìë¡œ ì „ë‹¬ ê°€ëŠ¥ (ì˜ˆ: --refine 'ê³ ê° ì¸í„°ë·° ìë™ ìš”ì•½ íˆ´')",
    )

    parser.add_argument(
        "--save-refined",
        type=str,
        nargs="?",
        const="inputs/last_refined.json",
        default=None,
        help="--refine ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ JSON íŒŒì¼ì— ì €ì¥. "
             "ê²½ë¡œ ë¯¸ì§€ì • ì‹œ ê¸°ë³¸ê°’: inputs/last_refined.json",
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Validate inputs and show configuration without running the crew.",
    )

    parser.add_argument(
        "--auto-revise",
        action="store_true",
        help="red_teamì´ FAIL íŒì • ì‹œ ìë™ìœ¼ë¡œ revision(revise_positioning + red_team_recheck)ì„ 1íšŒ ì‹¤í–‰. "
             "PASSë©´ ë°”ë¡œ final reportë¡œ ì§„í–‰.",
    )
    
    # ìš´ì˜ê¸‰ ê°€ë“œë ˆì¼ ì˜µì…˜
    parser.add_argument(
        "--safe-mode",
        action="store_true",
        help="ìš´ì˜ê¸‰ ì•ˆì „ ëª¨ë“œ: context í¬ê¸°ê°€ ì„ê³„ì¹˜ë¥¼ ë„˜ìœ¼ë©´ ìë™ ì¶•ì†Œ. "
             "TPM ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ê°€ë“œë ˆì¼ ì ìš©.",
    )
    
    # í›„ì† ëŒ€í™” ëª¨ë“œ
    parser.add_argument(
        "--chat",
        action="store_true",
        help="ë¦¬í¬íŠ¸ ìƒì„± í›„ í›„ì† ëŒ€í™” ëª¨ë“œ ì‹œì‘. "
             "ë¦¬í¬íŠ¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê±°ë‚˜ ë°˜ë¡ (Claim)ì„ ì œê¸°í•˜ë©´ AIê°€ ë‹µë³€í•©ë‹ˆë‹¤.",
    )

    args = parser.parse_args(argv)

    inputs: Dict[str, Any] = {}

    # 0) LLM ê¸°ë°˜ ì…ë ¥ êµ¬ì²´í™” ëª¨ë“œ (--refine)
    if args.refine is not None:
        initial_idea = args.refine if args.refine else None
        refine_result = refine_inputs(initial_idea)
        
        if not refine_result:
            print("ì…ë ¥ êµ¬ì²´í™”ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.", file=sys.stderr)
            return 2
        
        inputs = refine_result.get("inputs", {})
        confidence_flags = refine_result.get("confidence_flags", {})
        turns_used = refine_result.get("turns_used", 0)
        
        # ëª¨í˜¸í•œ í•„ë“œ ê²½ê³ 
        ambiguous_fields = [k for k, v in confidence_flags.items() if v == "ambiguous"]
        if ambiguous_fields:
            print(f"âš ï¸  ì¼ë¶€ í•„ë“œê°€ ëª¨í˜¸í•  ìˆ˜ ìˆì–´ìš”: {ambiguous_fields}")
            print("   ê²°ê³¼ë¥¼ í•´ì„í•  ë•Œ ì°¸ê³ í•˜ì„¸ìš”.\n")
        
        print(f"ğŸ“Š ì…ë ¥ êµ¬ì²´í™” ì™„ë£Œ (í„´ ìˆ˜: {turns_used})\n")
        
        # refine ê²°ê³¼ ì €ì¥
        save_data = {
            "inputs": inputs,
            "confidence_flags": confidence_flags,
            "turns_used": turns_used,
        }
        
        # --save-refined ì˜µì…˜ì´ ìˆìœ¼ë©´ ìë™ ì €ì¥
        if args.save_refined:
            save_path = Path(args.save_refined)
            save_path.parent.mkdir(parents=True, exist_ok=True)
            save_path.write_text(
                json.dumps(save_data, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )
            print(f"ğŸ’¾ ìë™ ì €ì¥ë¨: {save_path}\n")
        else:
            # ìˆ˜ë™ìœ¼ë¡œ ì €ì¥í• ì§€ ë¬¼ì–´ë´„
            print("ğŸ’¾ ì…ë ¥ê°’ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ì–´ìš”? (íŒŒì¼ëª… ì…ë ¥, ê±´ë„ˆë›°ë ¤ë©´ Enter)")
            user_save_path = input("   íŒŒì¼ëª… (ì˜ˆ: my_idea.json): ").strip()
            if user_save_path:
                if not user_save_path.endswith(".json"):
                    user_save_path += ".json"
                Path(user_save_path).write_text(
                    json.dumps(save_data, ensure_ascii=False, indent=2),
                    encoding="utf-8"
                )
                print(f"   âœ… ì €ì¥ë¨: {user_save_path}\n")

    # 1) JSON íŒŒì¼ ì…ë ¥ (--refineê³¼ ë³‘í–‰ ê°€ëŠ¥: refine ê²°ê³¼ë¥¼ ì˜¤ë²„ë¼ì´ë“œ)
    if args.input:
        loaded = _load_inputs_from_json(Path(args.input))
        inputs = {**inputs, **loaded}  # refine ê²°ê³¼ ìœ„ì— JSON ì˜¤ë²„ë¼ì´ë“œ

    # 2) CLI argsë¡œ ì˜¤ë²„ë¼ì´ë“œ/ë³´ì™„
    cli_map = {
        "idea_one_liner": args.idea,
        "target_customer": args.target,
        "problem_statement": args.problem,
        "current_alternatives": args.alternatives,
        "geo_market": args.geo,
        "business_type": args.type,
        "constraints": args.constraints,
        "success_definition": args.success,
    }
    for k, v in cli_map.items():
        if v:
            inputs[k] = v

    # 2.5) ì„ íƒì  í•„ë“œì— ê¸°ë³¸ê°’ ì ìš©
    for k, default_val in OPTIONAL_FIELDS.items():
        if not inputs.get(k):
            inputs[k] = default_val

    # 3) ì¸í„°ë™í‹°ë¸Œë¡œ ëˆ„ë½ ì±„ìš°ê¸°
    if args.interactive:
        inputs = _prompt_missing_fields(inputs)

    # 4) ê²€ì¦
    try:
        _validate_inputs(inputs)
    except Exception as e:
        print(f"âŒ Input error: {e}\n", file=sys.stderr)
        print("Tip: Use --refine (LLM ëŒ€í™”í˜•), --interactive, or --input JSON.\n", file=sys.stderr)
        return 2

    # 4.5) revision-only ì‹¤í–‰ìš© ê¸°ë³¸ê°’ ì¶”ê°€ (CrewAI í…œí”Œë¦¿ ë³€ìˆ˜ ìš”êµ¬ ì¶©ì¡±)
    # pass1ì—ì„œëŠ” ì´ ê°’ë“¤ì´ ë¹„ì–´ìˆê³ , contextì—ì„œ ì°¸ì¡°í•¨
    # pass2(revision-only)ì—ì„œëŠ” pass1 outputsë¡œ ì±„ì›Œì§
    inputs.setdefault("previous_positioning_output", "")
    inputs.setdefault("previous_red_team_output", "")
    inputs.setdefault("research_summary", "")
    inputs.setdefault("gap_hypotheses", "")

    # 5) Dry-run ëª¨ë“œ
    if args.dry_run:
        print("\n" + "=" * 60)
        print("ğŸ” DRY-RUN MODE (ì‹¤í–‰ ì—†ì´ ì„¤ì • í™•ì¸)")
        print("=" * 60)
        print("\nğŸ“‹ ì…ë ¥ê°’:")
        for k, v in inputs.items():
            print(f"   {k}: {v}")
        print("\nğŸ”§ í™˜ê²½ë³€ìˆ˜:")
        print(f"   SERPER_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('SERPER_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}")
        print(f"   OPENAI_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}")
        print(f"   MAIN_LLM_MODEL: {os.getenv('MAIN_LLM_MODEL', 'gpt-4.1 (ê¸°ë³¸ê°’)')}")
        print(f"   FAST_LLM_MODEL: {os.getenv('FAST_LLM_MODEL', 'gpt-4.1-mini (ê¸°ë³¸ê°’)')}")
        print(f"   NANO_LLM_MODEL: {os.getenv('NANO_LLM_MODEL', 'gpt-4.1-nano (ê¸°ë³¸ê°’, ë¯¸ì‚¬ìš©)')}")
        print("\nğŸ—ï¸  Crew êµ¬ì„± í…ŒìŠ¤íŠ¸...")
        try:
            crew, tracker = Step1CrewFactory().build(show_progress=False)
            print(f"   âœ… ì—ì´ì „íŠ¸ {len(crew.agents)}ê°œ ìƒì„±ë¨")
            print(f"   âœ… íƒœìŠ¤í¬ {len(crew.tasks)}ê°œ ìƒì„±ë¨")
            print("\nğŸ“ íƒœìŠ¤í¬ ì‹¤í–‰ ìˆœì„œ:")
            for i, task in enumerate(crew.tasks, 1):
                agent_role = getattr(task.agent, "role", "unknown")
                print(f"   {i}. {agent_role}")
        except Exception as e:
            print(f"   âŒ Crew êµ¬ì„± ì‹¤íŒ¨: {e}", file=sys.stderr)
            return 1
        print("\nâœ… Dry-run ì™„ë£Œ. ì‹¤ì œ ì‹¤í–‰í•˜ë ¤ë©´ --dry-run ì˜µì…˜ì„ ì œê±°í•˜ì„¸ìš”.")
        return 0

    # 6) ì‹¤í–‰
    out_dir = Path(args.out_dir)
    run_id = _generate_run_id(inputs)

    # --auto-revise: 2-pass ì‹¤í–‰ (FAILì´ë©´ revision í›„ ì¬ì‹¤í–‰)
    if args.auto_revise:
        print("\nğŸ”„ Auto-Revise ëª¨ë“œ: 1ì°¨ ì‹¤í–‰ ì‹œì‘...")
        
        # === 1ì°¨ ì‹¤í–‰ (revision ì—†ì´) ===
        start_time_pass1 = time.time()
        try:
            crew, tracker = Step1CrewFactory().build(include_revision=False)
            if tracker:
                tracker.print_header()
                # ì²« ë²ˆì§¸ íƒœìŠ¤í¬ ì‹œì‘ ì•Œë¦¼
                if tracker.task_order:
                    tracker.on_task_start(tracker.task_order[0])
            final_result = crew.kickoff(inputs=inputs)
            if tracker:
                tracker.print_summary()
        except Exception as e:
            print(f"âŒ Crew execution error (1ì°¨): {e}", file=sys.stderr)
            return 1
        elapsed_pass1 = time.time() - start_time_pass1
        
        # 1ì°¨ ê²°ê³¼ ì €ì¥ + metrics
        run_id_pass1 = f"{run_id}_pass1"
        try:
            _save_task_outputs(crew, out_dir=out_dir, run_id=run_id_pass1)
            _log_usage_metrics(crew, out_dir=out_dir, run_id=run_id_pass1, elapsed_seconds=elapsed_pass1)
            print(f"\nğŸ“ 1ì°¨ ê²°ê³¼ ì €ì¥: {out_dir / 'runs' / run_id_pass1}")
        except Exception as e:
            print(f"âš ï¸ 1ì°¨ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}", file=sys.stderr)
        
        # red_team verdict í™•ì¸ (ì €ì¥ëœ íŒŒì¼ì—ì„œë„ fallbackìœ¼ë¡œ ì½ê¸°)
        verdict, _ = _extract_verdict_from_crew(crew, out_dir=out_dir, run_id=run_id_pass1)
        print(f"\nğŸ” Red Team Verdict: {verdict}")
        
        # ìµœì¢… run_id ì¶”ì  (ë§ˆì§€ë§‰ ê³µí†µ ë¡œì§ì—ì„œ ì‚¬ìš©)
        final_run_id = run_id_pass1
        metrics_saved = True  # ì´ë¯¸ ì €ì¥ë¨
        
        if verdict == "PASS":
            print("âœ… PASS! Revision ë¶ˆí•„ìš”. ìµœì¢… ë¦¬í¬íŠ¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            final_text = str(final_result)
        
        elif verdict == "FAIL":
            print("âŒ FAIL! Revision-only ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")
            print("   (revision íƒœìŠ¤í¬ 3ê°œë§Œ ì‹¤í–‰: revise â†’ recheck â†’ report)")
            
            # === Pass1 outputsì—ì„œ í•„ìš”í•œ ë°ì´í„° ë¡œë“œ ===
            print("   ğŸ“‚ Pass1 outputs ë¡œë”© ì¤‘...")
            pass1_outputs = _load_pass1_outputs_for_revision(out_dir, run_id_pass1)
            
            start_time_pass2 = time.time()
            
            if not pass1_outputs.get("previous_positioning_output"):
                print("   âš ï¸ Pass1 positioning ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. ì „ì²´ ì¬ì‹¤í–‰ìœ¼ë¡œ fallback...")
                # Fallback: ì „ì²´ ì¬ì‹¤í–‰
                crew_v2, tracker_v2 = Step1CrewFactory().build(
                    include_revision=True, show_progress=True
                )
                if tracker_v2:
                    tracker_v2.print_header()
                    if tracker_v2.task_order:
                        tracker_v2.on_task_start(tracker_v2.task_order[0])
                final_result = crew_v2.kickoff(inputs=inputs)
            else:
                # Revision-only ì‹¤í–‰: inputsì— pass1 ê²°ê³¼ ì£¼ì…
                revision_inputs = {
                    **inputs,
                    **pass1_outputs,  # previous_positioning_output, previous_red_team_output ë“±
                }
                
                try:
                    crew_v2, tracker_v2 = Step1CrewFactory().build_revision_only(
                        show_progress=True
                    )
                    if tracker_v2:
                        tracker_v2.print_header()
                        if tracker_v2.task_order:
                            tracker_v2.on_task_start(tracker_v2.task_order[0])
                    final_result = crew_v2.kickoff(inputs=revision_inputs)
                    if tracker_v2:
                        tracker_v2.print_summary()
                except Exception as e:
                    print(f"âŒ Crew execution error (revision-only): {e}", file=sys.stderr)
                    return 1
            
            elapsed_pass2 = time.time() - start_time_pass2
            
            # 2ì°¨ ê²°ê³¼ ì €ì¥ + metrics
            run_id_pass2 = f"{run_id}_pass2_revised"
            try:
                _save_task_outputs(crew_v2, out_dir=out_dir, run_id=run_id_pass2)
                _log_usage_metrics(crew_v2, out_dir=out_dir, run_id=run_id_pass2, elapsed_seconds=elapsed_pass2)
                print(f"\nğŸ“ Revision ê²°ê³¼ ì €ì¥: {out_dir / 'runs' / run_id_pass2}")
            except Exception as e:
                print(f"âš ï¸ Revision ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}", file=sys.stderr)
            
            # ìµœì¢… verdict í™•ì¸ (red_team_recheckì—ì„œ - íŒŒì¼ fallback í¬í•¨)
            verdict_v2, _ = _extract_verdict_from_crew(crew_v2, out_dir=out_dir, run_id=run_id_pass2)
            print(f"\nğŸ” Red Team Recheck Verdict: {verdict_v2}")
            if verdict_v2 == "FAIL":
                print("âš ï¸ Revision í›„ì—ë„ FAILì…ë‹ˆë‹¤. ë¦¬í¬íŠ¸ì— ê²½ê³ ê°€ í¬í•¨ë©ë‹ˆë‹¤.")
            
            final_text = str(final_result)
            final_run_id = run_id_pass2
        
        else:  # UNKNOWN
            print("âš ï¸ VERDICTë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 1ì°¨ ê²°ê³¼ë¥¼ ìµœì¢…ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            final_text = str(final_result)
    
    else:
        # --auto-revise ì—†ìŒ: ê¸°ë³¸ ì‹¤í–‰ (revision ì—†ì´)
        metrics_saved = False
        
        start_time = time.time()
        try:
            crew, tracker = Step1CrewFactory().build(include_revision=False)
            if tracker:
                tracker.print_header()
                if tracker.task_order:
                    tracker.on_task_start(tracker.task_order[0])
            final_result = crew.kickoff(inputs=inputs)
            if tracker:
                tracker.print_summary()
        except Exception as e:
            print(f"âŒ Crew execution error: {e}", file=sys.stderr)
            return 1
        elapsed_time = time.time() - start_time
        
        final_text = str(final_result)
        
        # íƒœìŠ¤í¬ë³„ ê²°ê³¼ ì €ì¥
        try:
            _save_task_outputs(crew, out_dir=out_dir, run_id=run_id)
            print(f"\nâœ… Per-task outputs saved under: {out_dir / 'runs' / run_id}")
            print(f"âœ… Index: {(out_dir / 'runs' / run_id / '_index.json')}")
        except Exception as e:
            print(f"âš ï¸ Failed to save per-task outputs: {e}", file=sys.stderr)

    # 7) í† í° ì‚¬ìš©ëŸ‰/ë¹„ìš© ë¡œê¹… (auto-reviseì—ì„œëŠ” ì´ë¯¸ passë³„ë¡œ ì €ì¥ë¨)
    if not args.auto_revise:
        try:
            _log_usage_metrics(crew, out_dir=out_dir, run_id=run_id, elapsed_seconds=elapsed_time)
        except Exception as e:
            print(f"âš ï¸ Failed to log usage metrics: {e}", file=sys.stderr)

    # 8) ìµœì¢… ë¦¬í¬íŠ¸ ì €ì¥/ì¶œë ¥ (ë©”íƒ€ ì •ë³´ í—¤ë” ì¶”ê°€)
    report_header = _generate_report_header(inputs, run_id, args)
    final_text_with_header = report_header + final_text
    
    # ë¦¬í¬íŠ¸ ì €ì¥ (ì§€ì •ëœ ê²½ë¡œ ë˜ëŠ” reports/ í´ë”)
    if args.out:
        out_path = Path(args.out)
    else:
        # ê¸°ë³¸: outputs/reports/ í´ë”ì— ì €ì¥
        reports_dir = out_dir / "reports"
        reports_dir.mkdir(parents=True, exist_ok=True)
        out_path = reports_dir / f"{run_id}_report.md"
    
    _safe_write_text(out_path, final_text_with_header)
    print(f"\nâœ… Final report saved to: {out_path}")

    # 9) í›„ì† ëŒ€í™” ëª¨ë“œ (--chat)
    if args.chat:
        _start_report_chat(final_text, inputs)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())