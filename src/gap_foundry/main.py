from __future__ import annotations

import argparse
import json
import os
import re
import sys
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

# .env íŒŒì¼ ìë™ ë¡œë“œ
try:
    from dotenv import load_dotenv
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ ë¡œë“œ
    env_path = Path(__file__).resolve().parent.parent.parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)
except ImportError:
    # python-dotenvê°€ ì—†ìœ¼ë©´ ìˆ˜ë™ìœ¼ë¡œ ë¡œë“œ ì‹œë„
    env_path = Path(__file__).resolve().parent.parent.parent / ".env"
    if env_path.exists():
        with open(env_path) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ.setdefault(key.strip(), value.strip())

from gap_foundry.crew import Step1CrewFactory
from gap_foundry.input_refiner import refine_inputs


REQUIRED_KEYS = [
    "idea_one_liner",
    "target_customer",
    "problem_statement",
    "current_alternatives",
    "geo_market",
    "business_type",
]

# ì„ íƒì  í•„ë“œ (ê¸°ë³¸ê°’ ì œê³µ)
OPTIONAL_FIELDS = {
    "constraints": "íŠ¹ë³„í•œ ì œì•½ ì—†ìŒ",
    "success_definition": "ê²½ìŸì‚¬ ëŒ€ë¹„ ëª…í™•í•œ ì°¨ë³„ì  ë„ì¶œ",
}


def _load_inputs_from_json(path: Path) -> Dict[str, Any]:
    if not path.exists():
        raise FileNotFoundError(f"Input JSON not found: {path}")
    with path.open("r", encoding="utf-8") as f:
        data = json.load(f)
    if not isinstance(data, dict):
        raise ValueError("Input JSON must be an object/dict.")
    return data


def _prompt_missing_fields(data: Dict[str, Any]) -> Dict[str, Any]:
    for k in REQUIRED_KEYS:
        if not data.get(k):
            data[k] = input(f"{k}: ").strip()
    return data


def _validate_inputs(data: Dict[str, Any]) -> None:
    missing = [k for k in REQUIRED_KEYS if not data.get(k)]
    if missing:
        raise ValueError(f"Missing required input keys: {missing}")


# ============================================================================
# ìš´ì˜ê¸‰ ê°€ë“œë ˆì¼ #0: PreGate (ì…ë ¥ êµ¬ì²´ì„± ì²´í¬)
# ============================================================================

# PreGate ê·œì¹™ ë¡œë“œ (config/pregate_rules.yamlì—ì„œ)
def _load_pregate_rules() -> Dict[str, Any]:
    """PreGate ê·œì¹™ì„ YAML íŒŒì¼ì—ì„œ ë¡œë“œ"""
    rules_path = Path(__file__).parent / "config" / "pregate_rules.yaml"
    
    if rules_path.exists():
        try:
            import yaml
            with open(rules_path, encoding="utf-8") as f:
                loaded = yaml.safe_load(f)
                if loaded and isinstance(loaded, dict):
                    return loaded
        except ImportError:
            print("âš ï¸ PyYAML ë¯¸ì„¤ì¹˜. PreGate ê¸°ë³¸ ê·œì¹™ ì‚¬ìš© (pip install pyyaml)", file=sys.stderr)
        except Exception as e:
            print(f"âš ï¸ pregate_rules.yaml íŒŒì‹± ì‹¤íŒ¨: {e}. ê¸°ë³¸ ê·œì¹™ ì‚¬ìš©", file=sys.stderr)
    else:
        # íŒŒì¼ì´ ì—†ì„ ë•Œë§Œ ê²½ê³  (ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë³´í†µ ìˆìŒ)
        print("âš ï¸ config/pregate_rules.yaml ì—†ìŒ. ê¸°ë³¸ ê·œì¹™ ì‚¬ìš©", file=sys.stderr)
    
    # ê¸°ë³¸ê°’ (yaml íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¡œë“œ ì‹¤íŒ¨ ì‹œ) - ë³´ìˆ˜ì ìœ¼ë¡œ ë™ì‘
    return {
        "min_lengths": {
            "target_customer": 2,      # ê²½ê³ ìš©, FAIL ì•„ë‹˜
            "problem_statement": 11,
            "idea_one_liner": 15,
            "current_alternatives": 10,
        },
        "specific_short_targets_allowlist": [
            r"^ì˜ì‚¬$", r"^ê°„í˜¸ì‚¬$", r"^ì•½ì‚¬$", r"^êµì‚¬$", r"^ê°œë°œì$",
            r"^ë””ìì´ë„ˆ$", r"^í”„ë¦¬ëœì„œ$", r"^ì†Œìƒê³µì¸$", r"^ì§ì¥ì¸$",
            r"^doctors?$", r"^nurses?$", r"^developers?$", r"^freelancers?$",
        ],
        "vague_target_patterns": [
            r"^ëª¨ë“ \s*ì‚¬ëŒ", r"^ëˆ„êµ¬ë‚˜", r"^ì¼ë°˜ì¸", r"^ëª¨ë‘$",
            r"^ì‚¬ëŒë“¤$", r"^ì‚¬ìš©ì$", r"^ê³ ê°$",
            r"^everyone$", r"^anyone$", r"^all\s*people",
        ],
        "truism_problem_patterns": [
            # ì¶”ìƒ ëª…ì‚¬ + ì¤‘ìš”/í•„ìš” ì¡°í•©ë§Œ ì¡ìŒ
            r"(ê±´ê°•|í–‰ë³µ|ì„±ê³µ|ìê¸°ê³„ë°œ|ì‹œê°„ê´€ë¦¬|ìƒì‚°ì„±).*(ì¤‘ìš”í•˜ë‹¤|í•„ìš”í•˜ë‹¤)$",
            r"ì¢‹ë‹¤$", r"ë‚˜ì˜ë‹¤$",
            r"(health|happiness|success).*(is\s+important|is\s+needed)$",
        ],
        "action_patterns": {
            "strong": [
                r"ìë™í™”", r"ê³„ì‚°", r"ê¸°ë¡", r"ë¶„ì„", r"ì¶”ì²œ", r"ì•Œë¦¼", r"ì˜ˆì•½", r"ë§¤ì¹­",
                r"\bautomate\b", r"\bcalculate\b", r"\btrack\b", r"\banalyze\b",
            ],
            "weak": [
                r"í•˜ëŠ”", r"í•´ì£¼ëŠ”", r"ë•ëŠ”", r"ë§Œë“œëŠ”", r"ê´€ë¦¬",
                r"\bhelp\b", r"\bmake\b", r"\breduce\b", r"\bmanage\b",
            ],
        },
        "judgment": {"core_fail_threshold": 2},
    }


# ê·œì¹™ ìºì‹œ (í•œ ë²ˆë§Œ ë¡œë“œ)
_PREGATE_RULES: Optional[Dict[str, Any]] = None

def _get_pregate_rules() -> Dict[str, Any]:
    """PreGate ê·œì¹™ ê°€ì ¸ì˜¤ê¸° (ìºì‹œë¨)"""
    global _PREGATE_RULES
    if _PREGATE_RULES is None:
        _PREGATE_RULES = _load_pregate_rules()
    return _PREGATE_RULES


@dataclass
class PreGateResult:
    """PreGate ì²´í¬ ê²°ê³¼"""
    is_valid: bool
    fail_reasons: list
    warnings: list
    score: float  # 0.0 ~ 1.0 (ë‚®ì„ìˆ˜ë¡ ëª¨í˜¸í•¨)


def _pregate_check(data: Dict[str, Any]) -> PreGateResult:
    """
    PreGate: ì…ë ¥ì´ ëœë”© í…ŒìŠ¤íŠ¸ë¥¼ ëŒë¦´ ë§Œí¼ êµ¬ì²´ì ì¸ì§€ ì²´í¬.
    
    Q0(Idea Invariance)ì™€ ë¶„ë¦¬:
    - Q0: ì•„ì´ë””ì–´ê°€ 'ë³€í˜•'ë˜ì—ˆëŠ”ì§€ ì²´í¬
    - PreGate: ì…ë ¥ì´ 'ê²€ì¦ ê°€ëŠ¥í•œ ë‹¨ìœ„'ì¸ì§€ ì²´í¬
    
    v2 ê°œì„ :
    - ì§§ì§€ë§Œ êµ¬ì²´ì ì¸ íƒ€ê¹ƒ(ì˜ì‚¬, ê°œë°œì) allowlist ì§€ì›
    - ê¸¸ì´ ê¸°ì¤€ì€ warnìœ¼ë¡œ (FAIL ì•„ë‹˜)
    - action_patterns: strong/weak 2ë ˆë²¨ êµ¬ì¡°
    - truism_patterns: "ì¶”ìƒëª…ì‚¬+ì¤‘ìš”/í•„ìš”" ì¡°í•©ë§Œ ì¡ìŒ
    
    Returns:
        PreGateResult with:
        - is_valid: PreGate í†µê³¼ ì—¬ë¶€
        - fail_reasons: ì‹¤íŒ¨ ì´ìœ  ëª©ë¡
        - warnings: ê²½ê³  (í†µê³¼ëŠ” í–ˆì§€ë§Œ ì£¼ì˜ í•„ìš”)
        - score: 0.0 ~ 1.0 (êµ¬ì²´ì„± ì ìˆ˜, ë‚´ë¶€ìš©)
    """
    # ê·œì¹™ ë¡œë“œ
    rules = _get_pregate_rules()
    min_lengths = rules.get("min_lengths", {})
    allowlist = rules.get("specific_short_targets_allowlist", [])
    vague_target_patterns = rules.get("vague_target_patterns", [])
    truism_patterns = rules.get("truism_problem_patterns", [])
    action_patterns = rules.get("action_patterns", {})
    core_fail_threshold = rules.get("judgment", {}).get("core_fail_threshold", 2)
    
    fail_reasons = []
    warnings = []
    checks_passed = 0
    total_checks = 4
    
    target = data.get("target_customer", "").strip()
    target_lower = target.lower()
    problem = data.get("problem_statement", "").strip()
    problem_lower = problem.lower()
    idea = data.get("idea_one_liner", "").strip()
    alternatives = data.get("current_alternatives", "").strip()
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Check 1: íƒ€ê¹ƒì´ ë¹„íŠ¹ì •ì¸ê°€?
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    is_vague_target = False
    is_in_allowlist = False
    
    # Step 1a: allowlist ì²´í¬ (ì§§ì•„ë„ êµ¬ì²´ì ì¸ ì§êµ°)
    for pattern in allowlist:
        if re.search(pattern, target_lower, re.IGNORECASE):
            is_in_allowlist = True
            break
    
    # Step 1b: vague íŒ¨í„´ ì²´í¬ (allowlistë³´ë‹¤ ìš°ì„ ìˆœìœ„ ë†’ìŒ)
    for pattern in vague_target_patterns:
        if re.search(pattern, target_lower, re.IGNORECASE):
            is_vague_target = True
            break
    
    # Step 1c: ê¸¸ì´ ì²´í¬ (allowlistì— ì—†ê³  vagueë„ ì•„ë‹ ë•Œë§Œ warn)
    min_target_len = min_lengths.get("target_customer", 2)
    if not is_in_allowlist and not is_vague_target and len(target) < min_target_len:
        warnings.append(f"íƒ€ê¹ƒì´ ì§§ìŒ (ê¶Œì¥: ë” êµ¬ì²´ì ìœ¼ë¡œ): '{target}'")
    
    if is_vague_target:
        fail_reasons.append(f"íƒ€ê¹ƒì´ ë¹„íŠ¹ì •: '{target}'")
    else:
        checks_passed += 1
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Check 2: ë¬¸ì œê°€ ìƒì‹ ìˆ˜ì¤€ì¸ê°€?
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    is_truism = False
    for pattern in truism_patterns:
        if re.search(pattern, problem_lower, re.IGNORECASE):
            is_truism = True
            break
    
    # ê¸¸ì´ ì²´í¬: ë„ˆë¬´ ì§§ìœ¼ë©´ warn (FAIL ì•„ë‹˜)
    min_problem_len = min_lengths.get("problem_statement", 11)
    if len(problem) < min_problem_len and not is_truism:
        warnings.append(f"ë¬¸ì œ ì„¤ëª…ì´ ì§§ìŒ (ê¶Œì¥: ë” êµ¬ì²´ì ìœ¼ë¡œ): '{problem}'")
    
    if is_truism:
        fail_reasons.append(f"ë¬¸ì œê°€ ìƒì‹ ìˆ˜ì¤€: '{problem}'")
    else:
        checks_passed += 1
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Check 3: ì•„ì´ë””ì–´ê°€ í–‰ë™ì„ í¬í•¨í•˜ëŠ”ê°€? (strong/weak 2ë ˆë²¨)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    has_strong_action = False
    has_weak_action = False
    
    # action_patternsê°€ dict(ìƒˆ êµ¬ì¡°)ì¸ì§€ list(êµ¬ êµ¬ì¡°)ì¸ì§€ í™•ì¸
    if isinstance(action_patterns, dict):
        strong_patterns = action_patterns.get("strong", [])
        weak_patterns = action_patterns.get("weak", [])
    else:
        # êµ¬ êµ¬ì¡° í˜¸í™˜: ì „ë¶€ strongìœ¼ë¡œ ì·¨ê¸‰
        strong_patterns = action_patterns
        weak_patterns = []
    
    # strong íŒ¨í„´ ì²´í¬
    for pattern in strong_patterns:
        if re.search(pattern, idea, re.IGNORECASE):
            has_strong_action = True
            break
    
    # weak íŒ¨í„´ ì²´í¬ (strongì´ ì—†ì„ ë•Œë§Œ)
    if not has_strong_action:
        for pattern in weak_patterns:
            if re.search(pattern, idea, re.IGNORECASE):
                has_weak_action = True
                break
    
    # ì•„ì´ë””ì–´ ê¸¸ì´ ì²´í¬
    min_idea_len = min_lengths.get("idea_one_liner", 15)
    if len(idea) < min_idea_len:
        warnings.append(f"ì•„ì´ë””ì–´ê°€ ì§§ìŒ (ê¶Œì¥: ë” êµ¬ì²´ì ìœ¼ë¡œ): '{idea}'")
    
    # íŒì •: strong ìˆìœ¼ë©´ PASS, weakë§Œ ìˆìœ¼ë©´ warn + PASS, ë‘˜ ë‹¤ ì—†ìœ¼ë©´ FAIL
    if has_strong_action:
        checks_passed += 1
    elif has_weak_action:
        # weakë§Œ ìˆìœ¼ë©´ warn ì¶”ê°€í•˜ì§€ë§Œ PASSëŠ” ì‹œí‚´
        warnings.append(f"í–‰ë™ì´ ë²”ìš©ì  (ê¶Œì¥: ë” êµ¬ì²´ì ì¸ í–‰ë™ìœ¼ë¡œ): '{idea}'")
        checks_passed += 1
    else:
        fail_reasons.append(f"ì•„ì´ë””ì–´ì— êµ¬ì²´ì  í–‰ë™ì´ ì—†ìŒ: '{idea}'")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Check 4: í˜„ì¬ ëŒ€ì•ˆì´ ìˆëŠ”ê°€? (ê²½ê³ ë§Œ, ì‹¤íŒ¨ ì•„ë‹˜)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    min_alt_len = min_lengths.get("current_alternatives", 10)
    if not alternatives or len(alternatives) < min_alt_len:
        warnings.append("í˜„ì¬ ëŒ€ì•ˆì´ ëª…ì‹œë˜ì§€ ì•ŠìŒ")
    else:
        checks_passed += 1
    
    # ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0, ë‚´ë¶€ ë””ë²„ê¹…ìš©)
    score = checks_passed / total_checks
    
    # íŒì •: í•µì‹¬ 3ê°œ ì¤‘ threshold ì´ìƒ ì‹¤íŒ¨í•˜ë©´ PreGate FAIL
    core_fails = len([r for r in fail_reasons if "íƒ€ê¹ƒ" in r or "ë¬¸ì œ" in r or "í–‰ë™" in r])
    is_valid = core_fails < core_fail_threshold
    
    return PreGateResult(
        is_valid=is_valid,
        fail_reasons=fail_reasons,
        warnings=warnings,
        score=score,
    )


def _generate_pregate_fail_report(
    inputs: Dict[str, Any],
    pregate_result: PreGateResult,
    out_dir: Path,
    run_id: str,
) -> str:
    """
    PreGate FAIL ì‹œ ìƒì„±ë˜ëŠ” ë¦¬í¬íŠ¸.
    ì‚¬ìš©ìì—ê²Œ ë¬´ì—‡ì´ ë¶€ì¡±í•œì§€, ì–´ë–»ê²Œ ìˆ˜ì •í•˜ë©´ ì¢‹ì„ì§€ ì•ˆë‚´.
    """
    report_lines = [
        "<!--",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
        "â•‘                        ğŸ¯ GAP FOUNDRY - STEP1 REPORT                         â•‘",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
        f"â•‘  ğŸ“Œ Idea: {inputs.get('idea_one_liner', 'N/A')[:60]:<60} â•‘",
        f"â•‘  ğŸ‘¥ Target: {inputs.get('target_customer', 'N/A')[:58]:<58} â•‘",
        f"â•‘  ğŸ• Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}        |  ğŸ”– Run ID: {run_id[:30]} â•‘",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        "-->",
        "",
        "## ğŸš¦ Validation Gate ê²°ê³¼ ìš”ì•½",
        "",
        "### ìµœì¢… íŒì •",
        "**ğŸ”´ LANDING_NO**",
        "",
        "**ì‚¬ìœ **: ê²€ì¦ ë‹¨ìœ„ ì„±ë¦½ ë¶ˆê°€ (ëª¨í˜¸í•¨/ìƒì‹ ìˆ˜ì¤€)",
        "",
        "---",
        "",
        "## âŒ PreGate ì‹¤íŒ¨: ì´ˆê¸° ê²€ì¦ì„ ì‹œë„í•˜ê¸°ì— ì…ë ¥ì´ ë„ˆë¬´ ëª¨í˜¸í•©ë‹ˆë‹¤",
        "",
        "ì‹œì¥ ê²€ì¦(Landing Test, PoC, Interview ë“±)ì„ ì‹¤í–‰í•˜ë ¤ë©´ **êµ¬ì²´ì ì¸ ê²€ì¦ ë‹¨ìœ„**ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
        "í˜„ì¬ ì…ë ¥ì€ ë„ˆë¬´ ì¶”ìƒì ì´ì–´ì„œ ê²½ìŸ ë¶„ì„ì´ë‚˜ ì´ˆê¸° ì‹¤í—˜ì„ ì˜ë¯¸ ìˆê²Œ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "",
        "---",
        "",
        "## ğŸ” ë¶€ì¡±í•œ ë¶€ë¶„",
        "",
    ]
    
    for i, reason in enumerate(pregate_result.fail_reasons, 1):
        report_lines.append(f"### {i}. {reason.split(':')[0]}")
        report_lines.append(reason)
        report_lines.append("")
    
    if pregate_result.warnings:
        report_lines.append("## âš ï¸ ê²½ê³  (ê¶Œì¥ ìˆ˜ì •)")
        report_lines.append("")
        for warning in pregate_result.warnings:
            report_lines.append(f"- {warning}")
        report_lines.append("")
    
    # ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ë¦¬ë¼ì´íŠ¸ ì˜ˆì‹œ ìƒì„±
    user_idea = inputs.get('idea_one_liner', 'ê±´ê°• ì•±')
    user_target = inputs.get('target_customer', 'ëª¨ë“  ì‚¬ëŒ')
    
    report_lines.extend([
        "---",
        "",
        "## ğŸ”§ ì´ë ‡ê²Œ ê³ ì³ë³´ì„¸ìš”",
        "",
        "### âŒ í˜„ì¬ ì…ë ¥ (ë„ˆë¬´ ì¶”ìƒì )",
        f"- ì•„ì´ë””ì–´: {user_idea}",
        f"- íƒ€ê¹ƒ: {user_target}",
        f"- ë¬¸ì œ: {inputs.get('problem_statement', '')}",
        "",
        "### âœ… ë¦¬ë¼ì´íŠ¸ ì˜ˆì‹œ",
        "",
        "**ì˜ˆì‹œ 1**: ì•¼ê·¼ ë§ì€ 30ëŒ€ ì§ì¥ì¸ì´ ì €ë… 10ì‹œ ì´í›„ ê³¼ì‹ì„ ì¤„ì´ê²Œ ë•ëŠ” ì•±",
        "- íƒ€ê¹ƒ: ì£¼ 3íšŒ ì´ìƒ ì•¼ê·¼í•˜ëŠ” 30ëŒ€ ì‚¬ë¬´ì§",
        "- ë¬¸ì œ: ëŠ¦ì€ í‡´ê·¼ í›„ ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œë¡œ ê³¼ì‹ â†’ ì²´ì¤‘ ì¦ê°€ â†’ ë‹¤ìŒë‚  í›„íšŒ ë°˜ë³µ",
        "",
        "**ì˜ˆì‹œ 2**: í”„ë¦¬ëœì„œ ê°œë°œìë¥¼ ìœ„í•œ ì„¸ê¸ˆ ìë™ ê³„ì‚° ë° ì‹ ê³  ëŒ€í–‰ ì„œë¹„ìŠ¤",
        "- íƒ€ê¹ƒ: ì—° ë§¤ì¶œ 1ì–µ ë¯¸ë§Œì˜ 1ì¸ í”„ë¦¬ëœì„œ ê°œë°œì",
        "- ë¬¸ì œ: ë§¤ë…„ 5ì›” ì¢…í•©ì†Œë“ì„¸ ì‹ ê³  ì‹œ ê²½ë¹„ ì²˜ë¦¬ê°€ ë³µì¡í•´ì„œ ì„¸ë¬´ì‚¬ì—ê²Œ 30-50ë§Œì›ì„ ë‚´ê±°ë‚˜ ì§ì ‘ ë°¤ìƒˆ ì”¨ë¦„í•œë‹¤",
        "",
        "---",
        "",
        "### ë‹¤ìŒ ë‹¨ê³„",
        "",
        "`--refine` ì˜µì…˜ìœ¼ë¡œ ëŒ€í™”í˜• ì…ë ¥ êµ¬ì²´í™”ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”:",
        "```bash",
        "python3 -m gap_foundry.main --refine",
        "```",
        "",
        "---",
        "*Generated by [Gap Foundry](https://github.com/utopify/gap_foundry) - AI-powered Market Validation*",
    ])
    
    return "\n".join(report_lines)


# ============================================================================
# ìš´ì˜ê¸‰ ê°€ë“œë ˆì¼ #2: ê²½ìŸì‚¬ ìˆ˜ í›„ì²˜ë¦¬ ê°•ì œ ì»·
# ============================================================================

MAX_COMPETITORS_ITEMS = 8  # items ìµœëŒ€ 8ê°œ
MAX_COMPETITORS_CANDIDATES = 15  # candidates ìµœëŒ€ 15ê°œ


def _compact_competitors_output(raw_output: str) -> Tuple[str, bool]:
    """
    discover_competitors ì¶œë ¥ì„ íŒŒì‹±í•´ì„œ ê°•ì œ ì»·í•œë‹¤.
    
    Returns:
        (compacted_output, was_truncated)
    """
    # JSON ì¶”ì¶œ ì‹œë„
    json_match = re.search(r"```json\s*([\s\S]*?)\s*```", raw_output, re.IGNORECASE)
    if not json_match:
        # JSON ë¸”ë¡ì´ ì—†ìœ¼ë©´ { ... } ì°¾ê¸°
        first = raw_output.find("{")
        last = raw_output.rfind("}")
        if 0 <= first < last:
            json_str = raw_output[first:last + 1]
        else:
            return raw_output, False
    else:
        json_str = json_match.group(1)
    
    try:
        data = json.loads(json_str)
    except json.JSONDecodeError:
        return raw_output, False
    
    was_truncated = False
    
    # items ê°•ì œ ì»·
    if "items" in data and isinstance(data["items"], list):
        if len(data["items"]) > MAX_COMPETITORS_ITEMS:
            data["items"] = data["items"][:MAX_COMPETITORS_ITEMS]
            was_truncated = True
    
    # candidates ê°•ì œ ì»·
    if "candidates" in data and isinstance(data["candidates"], list):
        if len(data["candidates"]) > MAX_COMPETITORS_CANDIDATES:
            data["candidates"] = data["candidates"][:MAX_COMPETITORS_CANDIDATES]
            was_truncated = True
    
    # notes í•„ë“œ ì œê±° (ë¶ˆí•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ ê°ì†Œ)
    for item in data.get("items", []):
        if isinstance(item, dict) and "notes" in item:
            # notesë¥¼ 1ì¤„ë¡œ ì¶•ì•½
            notes = item.get("notes", "")
            if isinstance(notes, str) and len(notes) > 50:
                item["notes"] = notes[:50] + "..."
    
    compacted = "```json\n" + json.dumps(data, ensure_ascii=False, indent=2) + "\n```"
    return compacted, was_truncated


# ============================================================================
# ìš´ì˜ê¸‰ ê°€ë“œë ˆì¼ #5: Preflight ì•ˆì „ ì ê²€
# ============================================================================

CONTEXT_SIZE_THRESHOLD = 15000  # 15k ë¬¸ì ë„˜ìœ¼ë©´ ìœ„í—˜


def _preflight_check(crew, safe_mode: bool = False) -> Dict[str, Any]:
    """
    ì‹¤í–‰ ì „ context í¬ê¸°ë¥¼ ì²´í¬í•˜ê³ , ìœ„í—˜í•˜ë©´ ê²½ê³ /ìë™ ì¶•ì†Œ.
    
    Returns:
        {
            "total_chars": int,
            "is_safe": bool,
            "warnings": list[str],
            "auto_adjusted": bool,
        }
    """
    result = {
        "total_chars": 0,
        "is_safe": True,
        "warnings": [],
        "auto_adjusted": False,
    }
    
    # ì´ë¯¸ ì‹¤í–‰ëœ íƒœìŠ¤í¬ ê²°ê³¼ë“¤ì˜ í¬ê¸° í•©ì‚°
    tasks = getattr(crew, "tasks", [])
    for task in tasks:
        output = getattr(task, "output", None)
        if output:
            raw = getattr(output, "raw", "") or ""
            result["total_chars"] += len(raw)
    
    # ì„ê³„ì¹˜ ì²´í¬
    if result["total_chars"] > CONTEXT_SIZE_THRESHOLD:
        result["is_safe"] = False
        result["warnings"].append(
            f"âš ï¸ í˜„ì¬ context í¬ê¸°: {result['total_chars']:,}ì (ì„ê³„ì¹˜: {CONTEXT_SIZE_THRESHOLD:,}ì)"
        )
        
        if safe_mode:
            # safe_modeì—ì„œëŠ” ìë™ ì¶•ì†Œ í”Œë˜ê·¸ë§Œ ì„¤ì • (ì‹¤ì œ ì¶•ì†ŒëŠ” callerê°€ ì²˜ë¦¬)
            result["auto_adjusted"] = True
            result["warnings"].append("ğŸ”§ Safe Mode: ìë™ ì¶•ì†Œ ì ìš©ë¨")
    
    return result


def _print_preflight_warnings(preflight_result: Dict[str, Any]) -> None:
    """Preflight ê²½ê³  ì¶œë ¥"""
    if preflight_result["warnings"]:
        print("\n" + "â”€" * 60)
        print("ğŸ” Preflight ì ê²€ ê²°ê³¼")
        for w in preflight_result["warnings"]:
            print(f"   {w}")
        print("â”€" * 60 + "\n")


def _safe_write_text(path: Path, content: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")


def _log_usage_metrics(
    crew, 
    out_dir: Path, 
    run_id: str, 
    elapsed_seconds: Optional[float] = None
) -> Dict[str, Any]:
    """
    CrewAIì˜ usage_metricsë¥¼ ì¶”ì¶œí•˜ì—¬ ë¡œê¹…í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.
    
    CrewAIëŠ” crew.usage_metricsì—ì„œ í† í° ì‚¬ìš©ëŸ‰ì„ ì œê³µí•œë‹¤.
    https://docs.crewai.com/concepts/crews#crew-usage-metrics
    
    Args:
        crew: CrewAI Crew ê°ì²´
        out_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        run_id: ì‹¤í–‰ ID
        elapsed_seconds: ì‹¤í–‰ ì‹œê°„ (ì´ˆ)
    """
    metrics: Dict[str, Any] = {
        "run_id": run_id,
        "timestamp": datetime.now().isoformat(),
        "tokens": {},
        "estimated_cost_usd": None,
        "elapsed_seconds": elapsed_seconds,
        "elapsed_formatted": None,
    }
    
    # ì‹¤í–‰ ì‹œê°„ í¬ë§·íŒ…
    if elapsed_seconds is not None:
        minutes, seconds = divmod(int(elapsed_seconds), 60)
        if minutes > 0:
            metrics["elapsed_formatted"] = f"{minutes}ë¶„ {seconds}ì´ˆ"
        else:
            metrics["elapsed_formatted"] = f"{seconds}ì´ˆ"

    # CrewAI usage_metrics ì¶”ì¶œ
    usage = getattr(crew, "usage_metrics", None)
    if usage:
        # CrewAIì˜ usage_metrics êµ¬ì¡°ì— ë§ê²Œ ì¶”ì¶œ
        if isinstance(usage, dict):
            metrics["tokens"] = usage
        else:
            # UsageMetrics ê°ì²´ì¸ ê²½ìš°
            metrics["tokens"] = {
                "total_tokens": getattr(usage, "total_tokens", 0),
                "prompt_tokens": getattr(usage, "prompt_tokens", 0),
                "completion_tokens": getattr(usage, "completion_tokens", 0),
                "successful_requests": getattr(usage, "successful_requests", 0),
            }

    # ë¹„ìš© ì¶”ì • (ëŒ€ëµì ì¸ OpenAI ê°€ê²© ê¸°ì¤€)
    # GPT-4o: $2.50/1M input, $10/1M output
    # GPT-4o-mini: $0.15/1M input, $0.60/1M output
    # ì—¬ê¸°ì„œëŠ” í‰ê· ìœ¼ë¡œ ëŒ€ëµ ì¶”ì •
    total_tokens = metrics["tokens"].get("total_tokens", 0)
    if total_tokens > 0:
        # í˜¼í•© ì‚¬ìš© ê°€ì •: í‰ê·  $1.50/1M tokens (ë³´ìˆ˜ì  ì¶”ì •)
        metrics["estimated_cost_usd"] = round(total_tokens * 1.5 / 1_000_000, 4)

    # ì½˜ì†” ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“Š ì‹¤í–‰ í†µê³„ (Usage Metrics)")
    print("=" * 60)
    
    # ì‹œê°„ ë¨¼ì € í‘œì‹œ
    if metrics["elapsed_formatted"]:
        print(f"   â±ï¸  ì‹¤í–‰ ì‹œê°„: {metrics['elapsed_formatted']}")
    
    if metrics["tokens"]:
        for k, v in metrics["tokens"].items():
            print(f"   {k}: {v:,}" if isinstance(v, int) else f"   {k}: {v}")
    if metrics["estimated_cost_usd"]:
        print(f"   ğŸ’° ì¶”ì • ë¹„ìš©: ${metrics['estimated_cost_usd']:.4f} USD")
    else:
        print("   ğŸ’° ì¶”ì • ë¹„ìš©: (ë°ì´í„° ì—†ìŒ)")

    # íŒŒì¼ ì €ì¥
    metrics_path = out_dir / "runs" / run_id / "_usage_metrics.json"
    _safe_write_text(metrics_path, json.dumps(metrics, ensure_ascii=False, indent=2))
    print(f"   ğŸ“ ì €ì¥ë¨: {metrics_path}")

    return metrics


# ============================================================================
# íŒŒì¼ëª… ë§¤í•‘ (ì˜ë¯¸ ìˆëŠ” ì§§ì€ ì´ë¦„)
# ============================================================================

TASK_FILENAME_MAP = {
    "discover_competitors": "01_ê²½ìŸì‚¬_ë°œêµ´",
    "compact_competitors": "02_ê²½ìŸì‚¬_ì••ì¶•",
    "analyze_channels": "03_ì±„ë„_ë¶„ì„",
    "extract_value_props": "04_ê°€ì¹˜ì œì•ˆ_ì¶”ì¶œ",
    "summarize_channels_vp": "05_ì±„ë„VP_ìš”ì•½",
    "mine_gaps": "06_ë¹ˆí‹ˆ_ë°œêµ´",
    "summarize_research": "07_ë¦¬ì„œì¹˜_ìš”ì•½",
    "create_pov_and_positioning": "08_POV_í¬ì§€ì…”ë‹",
    "red_team_review": "09_ë ˆë“œíŒ€_ê²€í† ",
    "revise_positioning": "10_í¬ì§€ì…”ë‹_ìˆ˜ì •",
    "red_team_recheck": "11_ë ˆë“œíŒ€_ì¬ê²€í† ",
    "final_step1_report": "12_ìµœì¢…_ë¦¬í¬íŠ¸",
}

TASK_EMOJI_MAP = {
    "discover_competitors": "ğŸ”",
    "compact_competitors": "ğŸ“¦",
    "analyze_channels": "ğŸ“¢",
    "extract_value_props": "ğŸ’",
    "summarize_channels_vp": "ğŸ“‹",
    "mine_gaps": "ğŸ•³ï¸",
    "summarize_research": "ğŸ“‘",
    "create_pov_and_positioning": "ğŸ¯",
    "red_team_review": "ğŸ”´",
    "revise_positioning": "âœï¸",
    "red_team_recheck": "ğŸ”´",
    "final_step1_report": "ğŸ“Š",
}


def _generate_run_id(inputs: Dict[str, Any]) -> str:
    """
    ì˜ë¯¸ ìˆëŠ” run_id ìƒì„±
    í˜•ì‹: YYYY-MM-DD_ì•„ì´ë””ì–´ìš”ì•½_íƒ€ì…
    ì˜ˆ: 2026-01-16_AIì´ë ¥ì„œìë™ì‘ì„±_B2C
    """
    date_str = datetime.now().strftime("%Y-%m-%d_%H%M")
    
    # ì•„ì´ë””ì–´ì—ì„œ í•µì‹¬ ë‹¨ì–´ ì¶”ì¶œ (í•œê¸€/ì˜ë¬¸, ìµœëŒ€ 15ì)
    idea = inputs.get("idea_one_liner", "unknown")
    # ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  í•µì‹¬ë§Œ
    idea_clean = re.sub(r"[^\wê°€-í£]", "", idea)[:15]
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ íƒ€ì…
    biz_type = inputs.get("business_type", "")
    
    # ì¡°í•©
    run_id = f"{date_str}_{idea_clean}"
    if biz_type:
        run_id += f"_{biz_type}"
    
    # íŒŒì¼ì‹œìŠ¤í…œ ì•ˆì „í•˜ê²Œ
    run_id = re.sub(r"[/\\:*?\"<>|]", "_", run_id)
    
    return run_id


def _extract_task_id(task) -> str:
    """
    Task ê°ì²´ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‹ë³„ìë¥¼ ë½‘ê¸° ìœ„í•œ í—¬í¼.
    CrewAI ë²„ì „ì— ë”°ë¼ name/idê°€ ì—†ì„ ìˆ˜ ìˆì–´ description ì²« ì¤„ë¡œ ëŒ€ì²´.
    """
    # ìš°ì„ ìˆœìœ„: name -> id -> description prefix
    name = getattr(task, "name", None)
    if isinstance(name, str) and name.strip():
        return name.strip()

    tid = getattr(task, "id", None)
    if isinstance(tid, str) and tid.strip():
        return tid.strip()

    desc = getattr(task, "description", "") or ""
    first = desc.strip().splitlines()[0] if desc.strip() else "task"
    first = first[:40].strip().replace(" ", "_")
    return first or "task"


def _get_friendly_filename(task_id: str, index: int) -> str:
    """íƒœìŠ¤í¬ IDë¥¼ ì˜ë¯¸ ìˆëŠ” íŒŒì¼ëª…ìœ¼ë¡œ ë³€í™˜"""
    # ë§¤í•‘ì—ì„œ ì°¾ê¸°
    if task_id in TASK_FILENAME_MAP:
        return TASK_FILENAME_MAP[task_id]
    
    # ë§¤í•‘ì— ì—†ìœ¼ë©´ ê¸°ë³¸ í˜•íƒœ
    return f"{index:02d}_{task_id[:30]}"


def _generate_task_header(task_id: str, run_id: str) -> str:
    """íƒœìŠ¤í¬ë³„ í—¤ë” ìƒì„±"""
    emoji = TASK_EMOJI_MAP.get(task_id, "ğŸ“„")
    friendly_name = TASK_FILENAME_MAP.get(task_id, task_id).replace("_", " ").split("_", 1)[-1] if "_" in TASK_FILENAME_MAP.get(task_id, "") else task_id
    
    header = f"""<!--
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {emoji} Gap Foundry - {friendly_name}
â”‚ Run ID: {run_id}
â”‚ Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
-->

"""
    return header


def _generate_report_header(
    inputs: Dict[str, Any], 
    run_id: str, 
    args,
    run_started_at: str = "",
    run_finished_at: str = "",
    total_elapsed: float = 0,
    stage_times: Optional[Dict[str, float]] = None,
    final_verdict: str = ""
) -> str:
    """ìµœì¢… ë¦¬í¬íŠ¸ ë©”íƒ€ ì •ë³´ í—¤ë” + ì‹¤í–‰ ì •ë³´ + Idea Anchor ìƒì„± (ì½”ë“œê°€ ì •í™•í•œ ì‹œê°„ ì‚½ì…)"""
    idea = inputs.get("idea_one_liner", "N/A")
    target = inputs.get("target_customer", "N/A")
    problem = inputs.get("problem_statement", "N/A")
    geo = inputs.get("geo_market", "N/A")
    biz_type = inputs.get("business_type", "N/A")
    
    mode = "Safe Mode" if getattr(args, "safe_mode", False) else "Standard"
    if getattr(args, "auto_revise", False):
        mode += " + Auto-Revise"
    
    # Verdict ì´ëª¨ì§€
    verdict_emoji = "ğŸŸ¢" if final_verdict == "LANDING_GO" else "ğŸŸ¡" if final_verdict == "LANDING_HOLD" else "ğŸ”´" if final_verdict == "LANDING_NO" else "âšª"
    verdict_msg = "ì‹œì¥ ê²€ì¦ ì‹œë„ ê°€ì¹˜ ì¶©ë¶„" if final_verdict == "LANDING_GO" else "ì‹¤í—˜ ì„¤ê³„ ë³´ì™„ í•„ìš”" if final_verdict == "LANDING_HOLD" else "ì…ë ¥ êµ¬ì²´í™”/ì¬ê²€í†  ê¶Œì¥"
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì‹¤í–‰ ì‹œê°„ í¬ë§·íŒ… (SSOT: Single Source of Truth)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if total_elapsed > 0:
        mins = int(total_elapsed // 60)
        secs = int(total_elapsed % 60)
        elapsed_str = f"{mins}ë¶„ {secs}ì´ˆ ({total_elapsed:.1f}ì´ˆ)"
    else:
        elapsed_str = "N/A"
    
    # Stageë³„ ì‹œê°„ ë¬¸ìì—´
    stage_times_str = ""
    if stage_times:
        for stage_name, stage_sec in stage_times.items():
            stage_mins = int(stage_sec // 60)
            stage_secs = int(stage_sec % 60)
            stage_times_str += f"  - {stage_name}: {stage_mins}ë¶„ {stage_secs}ì´ˆ\n"
    else:
        stage_times_str = "  - N/A\n"
    
    header = f"""<!--
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        ğŸ¯ GAP FOUNDRY - STEP1 REPORT                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ“Œ Idea: {idea[:60]:<62} â•‘
â•‘  ğŸ‘¥ Target: {target[:55]:<60} â•‘
â•‘  ğŸŒ Market: {geo:<10}  |  ğŸ’¼ Type: {biz_type:<8}  |  âš™ï¸ Mode: {mode:<15} â•‘
â•‘  ğŸ• Generated: {run_finished_at or datetime.now().strftime("%Y-%m-%d %H:%M:%S"):<25}  |  ğŸ”– Run ID: {run_id:<12} â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-->

## ğŸ§© ê²€ì¦ ëŒ€ìƒ ì•„ì´ë””ì–´ (Idea Anchor)

- **ì•„ì´ë””ì–´ ì›ë¬¸**  
  â†’ {idea}

- **í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œ**  
  â†’ {problem}

- **íƒ€ê¹ƒ ê³ ê°**  
  â†’ {target}

- **ì˜ë„í•œ í•µì‹¬ í–‰ë™**  
  â†’ {inputs.get("current_alternatives", "ëŒ€ì•ˆ ì—†ìŒ")}ì„ ëŒ€ì²´í•˜ì—¬ ì´ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©

â€» **ì•„ë˜ ëª¨ë“  íŒë‹¨ì€ ì´ ì•„ì´ë””ì–´ë¥¼ ë³€í˜•í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€í•œ ìƒíƒœì—ì„œ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤.**

---

## ğŸš¦ Validation Gate ê²°ê³¼ ìš”ì•½

### ìµœì¢… íŒì •
**{verdict_emoji} {final_verdict or "íŒì • ëŒ€ê¸°"}: {verdict_msg}**

---

"""
    return header


def _generate_report_footer(
    metrics: Dict[str, Any],
    run_started_at: str = "",
    run_finished_at: str = "",
    total_elapsed: float = 0,
    stage_times: Optional[Dict[str, float]] = None,
) -> str:
    """ë¦¬í¬íŠ¸ í‘¸í„° ìƒì„± (ì‹¤í–‰ ì •ë³´ + í† í°/ë¹„ìš© - ë§¨ ë§ˆì§€ë§‰ì— í‘œì‹œ)"""
    tokens = metrics.get("tokens", {})
    total_tokens = tokens.get("total_tokens", 0)
    prompt_tokens = tokens.get("prompt_tokens", 0)
    completion_tokens = tokens.get("completion_tokens", 0)
    requests = tokens.get("successful_requests", 0)
    cost = metrics.get("estimated_cost_usd", 0)
    
    # ì‹¤í–‰ ì‹œê°„ í¬ë§·íŒ…
    if total_elapsed > 0:
        mins = int(total_elapsed // 60)
        secs = int(total_elapsed % 60)
        elapsed_str = f"{mins}ë¶„ {secs}ì´ˆ ({total_elapsed:.1f}ì´ˆ)"
    else:
        elapsed_str = "N/A"
    
    # Stageë³„ ì‹œê°„ ë¬¸ìì—´
    stage_times_str = ""
    if stage_times:
        for stage_name, stage_sec in stage_times.items():
            stage_mins = int(stage_sec // 60)
            stage_secs = int(stage_sec % 60)
            stage_times_str += f"  - {stage_name}: {stage_mins}ë¶„ {stage_secs}ì´ˆ\n"
    else:
        stage_times_str = "  - N/A\n"
    
    footer = f"""

---

## ğŸ“Š ì‹¤í–‰ ì •ë³´ & ë¹„ìš©

### â±ï¸ ì‹¤í–‰ ì‹œê°„
- **ì´ ì‹¤í–‰ ì‹œê°„**: {elapsed_str}
- **ì‹¤í–‰ ì‹œì‘**: {run_started_at or "N/A"}
- **ì‹¤í–‰ ì¢…ë£Œ**: {run_finished_at or "N/A"}
- **í¬í•¨ ë‹¨ê³„**:
{stage_times_str}
### ğŸ’° í† í°/ë¹„ìš© í†µê³„

| í•­ëª© | ê°’ |
|------|-----|
| ğŸ“ ì´ í† í° | {total_tokens:,} |
| ğŸ“¥ ì…ë ¥ í† í° | {prompt_tokens:,} |
| ğŸ“¤ ì¶œë ¥ í† í° | {completion_tokens:,} |
| ğŸ”„ API ìš”ì²­ | {requests:,}íšŒ |
| ğŸ’° ì¶”ì • ë¹„ìš© | **${cost:.4f} USD** |

---
*Generated by [Gap Foundry](https://github.com/utopify/gap_foundry) - AI-powered Market Validation*
"""
    return footer


def _save_task_outputs(
    crew,
    out_dir: Path,
    run_id: str,
    also_save_json_when_possible: bool = True,
) -> Dict[str, str]:
    """
    crew.kickoff() í›„ crew.tasksë¥¼ ìˆœíšŒí•˜ë©´ì„œ ê° task.outputì„ ì €ì¥.
    TaskOutputì€ task.output.raw / task.output.json_dict ë“±ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥.
    """
    outputs_dir = out_dir / "runs" / run_id
    outputs_dir.mkdir(parents=True, exist_ok=True)

    index: Dict[str, str] = {}

    for i, task in enumerate(getattr(crew, "tasks", []) or []):
        task_id = _extract_task_id(task)
        
        # ì˜ë¯¸ ìˆëŠ” íŒŒì¼ëª… ìƒì„±
        file_stem = _get_friendly_filename(task_id, i + 1)
        raw_path = outputs_dir / f"{file_stem}.md"

        task_output = getattr(task, "output", None)
        if task_output is None:
            _safe_write_text(raw_path, "# (No output)\n")
            index[task_id] = str(raw_path)
            continue

        raw = getattr(task_output, "raw", "") or ""
        
        # ìµœì¢… ë¦¬í¬íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° í—¤ë” ì¶”ê°€
        if task_id != "final_step1_report":
            header = _generate_task_header(task_id, run_id)
            raw = header + raw
        
        _safe_write_text(raw_path, raw)
        index[task_id] = str(raw_path)

        # ê°€ëŠ¥í•˜ë©´ JSONë„ ì €ì¥
        if also_save_json_when_possible:
            json_dict = getattr(task_output, "json_dict", None)
            if isinstance(json_dict, dict):
                json_path = outputs_dir / f"{file_stem}.json"
                _safe_write_text(json_path, json.dumps(json_dict, ensure_ascii=False, indent=2))
                index[task_id + "_json"] = str(json_path)

    # ì¸ë±ìŠ¤ íŒŒì¼ ì €ì¥
    index_path = outputs_dir / "_index.json"
    _safe_write_text(index_path, json.dumps(index, ensure_ascii=False, indent=2))

    return index


def _parse_verdict_from_text(text: str) -> Optional[str]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ VERDICTë¥¼ íŒŒì‹±í•œë‹¤.
    
    ì‹ ê·œ ì‹œì¥ê²€ì¦ ê²Œì´íŠ¸ íŒì • ì²´ê³„:
    - VALIDATION_GO (ë˜ëŠ” LANDING_GO): ì´ˆê¸° ê²€ì¦ ì‹œë„ ê°€ì¹˜ ì¶©ë¶„
    - VALIDATION_HOLD (ë˜ëŠ” LANDING_HOLD): ì‹¤í—˜ ì„¤ê³„ ë³´ì™„ í•„ìš”
    - VALIDATION_NO (ë˜ëŠ” LANDING_NO): ê²€ì¦ ë‹¨ìœ„ ë¯¸ì„±ë¦½
    
    (ë‚´ë¶€ ë¡œì§ì€ LANDING_* í¬ë§·ìœ¼ë¡œ í†µì¼í•˜ì—¬ ì²˜ë¦¬)
    
    âš ï¸ word boundary (\b) ì‚¬ìš©ìœ¼ë¡œ ë¶€ë¶„ ë§¤ì¹­ ë°©ì§€
    """
    if not text:
        return None
    
    # 1) ì‹ ê·œ í¬ë§· ìš°ì„  (word boundaryë¡œ ì •í™•í•œ ë§¤ì¹­)
    m = re.search(
        r"VERDICT\s*:\s*(LANDING_GO|LANDING_HOLD|LANDING_NO|VALIDATION_GO|VALIDATION_HOLD|VALIDATION_NO)\b",
        text,
        re.IGNORECASE
    )
    if m:
        verdict = m.group(1).upper()
        # ë‚´ë¶€ ë¡œì§ í˜¸í™˜ì„ ìœ„í•´ VALIDATION -> LANDING ë³€í™˜
        return verdict.replace("VALIDATION_", "LANDING_")
    
    # 2) ë ˆê±°ì‹œ í¬ë§· fallback (PASS â†’ GO, FAIL â†’ NO)
    m2 = re.search(r"VERDICT\s*:\s*(PASS|FAIL)\b", text, re.IGNORECASE)
    if m2:
        legacy = m2.group(1).upper()
        return "LANDING_GO" if legacy == "PASS" else "LANDING_NO"
    
    return None


def _extract_verdict_from_crew(crew, out_dir: Optional[Path] = None, run_id: Optional[str] = None) -> Tuple[str, str]:
    """
    Crew ì‹¤í–‰ í›„ red_team_review ë˜ëŠ” red_team_recheck íƒœìŠ¤í¬ì—ì„œ VERDICTë¥¼ ì¶”ì¶œí•œë‹¤.
    
    Args:
        crew: CrewAI Crew ê°ì²´
        out_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (íŒŒì¼ì—ì„œ fallback ì½ê¸°ìš©)
        run_id: ì‹¤í–‰ ID (íŒŒì¼ì—ì„œ fallback ì½ê¸°ìš©)
    
    Returns:
        (verdict, raw_output)
        - verdict: "LANDING_GO" | "LANDING_HOLD" | "LANDING_NO" | "UNKNOWN"
                   (ë ˆê±°ì‹œ PASS â†’ LANDING_GO, FAIL â†’ LANDING_NOë¡œ ìë™ ë³€í™˜)
        - raw_output: red_team íƒœìŠ¤í¬ì˜ ì „ì²´ ì¶œë ¥
    """
    # red_team íƒœìŠ¤í¬ ì°¾ê¸° - ë‹¤ì¤‘ ë°©ì‹ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ
    red_team_tasks = []
    for task in getattr(crew, "tasks", []) or []:
        # 1) agent roleë¡œ ì°¾ê¸° (ê°€ì¥ ì•ˆì „)
        agent = getattr(task, "agent", None)
        agent_role = (getattr(agent, "role", "") or "").lower()
        if "red_team" in agent_role or "ë ˆë“œíŒ€" in agent_role or "ë°˜ì¦" in agent_role:
            red_team_tasks.append(task)
            continue
        
        # 2) description ì „ì²´ì—ì„œ ì°¾ê¸° (fallback)
        desc = (getattr(task, "description", "") or "").lower()
        if "red_team" in desc or "ê³µê²©ì ìœ¼ë¡œ ê²€í† " in desc or "verdict" in desc:
            red_team_tasks.append(task)
            continue
        
        # 3) task_id íŒ¨í„´ìœ¼ë¡œ ì°¾ê¸° (ë§ˆì§€ë§‰ fallback)
        task_id = _extract_task_id(task)
        if "red_team" in task_id.lower():
            red_team_tasks.append(task)
    
    # === ë°©ë²• 1: task.outputì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° ===
    if red_team_tasks:
        # ë§ˆì§€ë§‰ red_team íƒœìŠ¤í¬ (recheckì´ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©)
        last_red_team = red_team_tasks[-1]
        task_output = getattr(last_red_team, "output", None)
        
        if task_output is not None:
            raw = getattr(task_output, "raw", "") or str(task_output) or ""
            verdict = _parse_verdict_from_text(raw)
            if verdict:
                return verdict, raw
    
    # === ë°©ë²• 2: ì €ì¥ëœ íŒŒì¼ì—ì„œ ì½ê¸° (fallback) ===
    if out_dir and run_id:
        run_dir = out_dir / "runs" / run_id
        if run_dir.exists():
            # ë ˆë“œíŒ€ ê´€ë ¨ íŒŒì¼ ì°¾ê¸° (09_ë ˆë“œíŒ€_ê²€í†  ë˜ëŠ” 11_ë ˆë“œíŒ€_ì¬ê²€í† )
            red_team_files = []
            for f in sorted(run_dir.glob("*.md")):
                fname_lower = f.name.lower()
                if "ë ˆë“œíŒ€" in fname_lower or "red_team" in fname_lower:
                    red_team_files.append(f)
            
            # ë§ˆì§€ë§‰ ë ˆë“œíŒ€ íŒŒì¼ì—ì„œ VERDICT íŒŒì‹±
            if red_team_files:
                last_file = red_team_files[-1]
                try:
                    content = last_file.read_text(encoding="utf-8")
                    verdict = _parse_verdict_from_text(content)
                    if verdict:
                        return verdict, content
                except Exception:
                    pass
    
    # === ë°©ë²• 3: crewì˜ ì „ì²´ ê²°ê³¼ì—ì„œ ì°¾ê¸° ===
    # CrewAIì˜ ê²°ê³¼ ê°ì²´ì—ì„œ ì§ì ‘ ì°¾ê¸°
    crew_result = getattr(crew, "result", None) or getattr(crew, "_result", None)
    if crew_result:
        result_str = str(crew_result)
        verdict = _parse_verdict_from_text(result_str)
        if verdict:
            return verdict, result_str
    
    return "UNKNOWN", ""


def _get_task_output_by_name(crew, task_name_pattern: str) -> str:
    """íŠ¹ì • íƒœìŠ¤í¬ì˜ ì¶œë ¥ì„ ê°€ì ¸ì˜¨ë‹¤."""
    for task in getattr(crew, "tasks", []) or []:
        task_id = _extract_task_id(task)
        if task_name_pattern.lower() in task_id.lower():
            task_output = getattr(task, "output", None)
            if task_output:
                return getattr(task_output, "raw", "") or ""
    return ""


# ============================================================================
# í›„ì† ëŒ€í™” ê¸°ëŠ¥ (ë¦¬í¬íŠ¸ì— ëŒ€í•œ Q&A)
# ============================================================================

def _start_report_chat(report_text: str, inputs: Dict[str, Any]) -> None:
    """
    ë¦¬í¬íŠ¸ ì™„ë£Œ í›„ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ëŠ” ëª¨ë“œ.
    ì‚¬ìš©ìê°€ ë¦¬í¬íŠ¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê±°ë‚˜ ë°˜ë¡ (Claim)ì„ ì œê¸°í•˜ë©´ LLMì´ ë‹µë³€í•œë‹¤.
    """
    try:
        from crewai import LLM
    except ImportError:
        print("âš ï¸ CrewAI LLMì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€í™” ëª¨ë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # LLM ì´ˆê¸°í™” (main ëª¨ë¸ ì‚¬ìš©)
    model = os.getenv("MAIN_LLM_MODEL", "gpt-4.1")
    llm = LLM(model=model)
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    idea = inputs.get("idea_one_liner", "N/A")
    target = inputs.get("target_customer", "N/A")
    
    system_prompt = f"""ë‹¹ì‹ ì€ ì‹œì¥ê²€ì¦ ë¦¬í¬íŠ¸ì— ëŒ€í•´ í† ë¡ í•˜ëŠ” ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

[ì•„ì´ë””ì–´ ë°°ê²½]
- ì•„ì´ë””ì–´: {idea}
- íƒ€ê¹ƒ ê³ ê°: {target}

[ë¦¬í¬íŠ¸ ë‚´ìš©]
{report_text[:8000]}  # í† í° ì œí•œì„ ìœ„í•´ ì•ë¶€ë¶„ë§Œ

[ì—­í• ]
- ì‚¬ìš©ìê°€ ë¦¬í¬íŠ¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´ ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
- ì‚¬ìš©ìê°€ ë°˜ë¡ (Claim)ì„ ì œê¸°í•˜ë©´:
  1. ë¨¼ì € ê·¸ ê´€ì ì„ ì¸ì •í•˜ê³ 
  2. ë¦¬í¬íŠ¸ì˜ ê·¼ê±°ì™€ ë¹„êµ ë¶„ì„í•˜ê³ 
  3. ê°€ëŠ¥í•˜ë‹¤ë©´ ìƒˆë¡œìš´ ì‹œê°ì„ ì œì‹œí•˜ì„¸ìš”.
- ì‚¬ìš©ìì˜ ê´€ì ì´ íƒ€ë‹¹í•˜ë©´ ì¸ì •í•˜ê³ , ë¦¬í¬íŠ¸ ê²°ë¡  ìˆ˜ì •ì„ ì œì•ˆí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
- í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- ë‹µë³€ì€ ê°„ê²°í•˜ê²Œ (3-5ë¬¸ë‹¨ ì´ë‚´).
"""
    
    conversation_history = [{"role": "system", "content": system_prompt}]
    
    print("\n" + "=" * 60)
    print("ğŸ’¬ ë¦¬í¬íŠ¸ í›„ì† ëŒ€í™” ëª¨ë“œ")
    print("=" * 60)
    print("ë¦¬í¬íŠ¸ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ë‚˜ ë°˜ë¡ ì´ ìˆìœ¼ë©´ ììœ ë¡­ê²Œ ë§ì”€í•˜ì„¸ìš”.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit', 'exit', ë˜ëŠ” 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("=" * 60 + "\n")
    
    while True:
        try:
            user_input = input("ğŸ“ ë‚˜: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\n\nëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ‘‹")
            break
        
        if not user_input:
            continue
        
        if user_input.lower() in ["quit", "exit", "q", "ì¢…ë£Œ", "ë", "ë‚˜ê°€ê¸°"]:
            print("\nëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ‘‹")
            break
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        conversation_history.append({"role": "user", "content": user_input})
        
        # LLM í˜¸ì¶œ
        try:
            response = llm.call(messages=conversation_history)
            
            # ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            conversation_history.append({"role": "assistant", "content": response})
            
            print(f"\nğŸ¤– AI: {response}\n")
            
        except Exception as e:
            print(f"\nâš ï¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            print("   ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n")
            # ì‹¤íŒ¨í•œ ë©”ì‹œì§€ëŠ” íˆìŠ¤í† ë¦¬ì—ì„œ ì œê±°
            conversation_history.pop()


def _load_pass1_outputs_for_revision(out_dir: Path, run_id_pass1: str) -> Dict[str, str]:
    """
    Pass1 outputsì—ì„œ revisionì— í•„ìš”í•œ íŒŒì¼ë“¤ì„ ì½ì–´ì˜¨ë‹¤.
    
    Returns:
        Dict with keys: previous_positioning_output, previous_red_team_output, research_summary
    """
    pass1_dir = out_dir / "runs" / run_id_pass1
    
    def read_md(pattern: str) -> str:
        """íŒ¨í„´ì´ í¬í•¨ëœ md íŒŒì¼ ì½ê¸°"""
        for f in pass1_dir.glob("*.md"):
            if pattern.lower() in f.name.lower():
                try:
                    return f.read_text(encoding="utf-8")
                except Exception:
                    continue
        return ""
    
    return {
        "previous_positioning_output": (
            read_md("create_pov") or read_md("positioning") or read_md("pov")
        ),
        "previous_red_team_output": (
            read_md("red_team_review") or read_md("red_team")
        ),
        "research_summary": (
            read_md("summarize") or read_md("summary")
        ),
        "gap_hypotheses": (
            read_md("mine_gaps") or read_md("gap")
        ),
    }


def main(argv: Optional[list[str]] = None) -> int:
    parser = argparse.ArgumentParser(
        description="Gap Foundry - STEP1 (Competitive Analysis + Idea Refinement) runner"
    )

    parser.add_argument(
        "--input",
        type=str,
        default="",
        help="Path to input JSON file. If omitted, uses CLI args.",
    )
    parser.add_argument("--idea", type=str, default="", help="One-liner idea")
    parser.add_argument("--target", type=str, default="", help="Target customer")
    parser.add_argument("--problem", type=str, default="", help="Problem statement")
    parser.add_argument(
        "--alternatives",
        type=str,
        default="",
        help="Current alternatives (comma-separated or free text; ideally 3+)",
    )
    parser.add_argument("--geo", type=str, default="KR", help="Geo market (KR/Global)")
    parser.add_argument("--type", type=str, default="B2B", help="Business type (B2B/B2C)")
    parser.add_argument("--constraints", type=str, default="", help="Constraints")
    parser.add_argument("--success", type=str, default="", help="Success definition (STEP1)")

    # ìµœì¢… ë¦¬í¬íŠ¸ ì €ì¥ ê²½ë¡œ(ì˜µì…˜)
    parser.add_argument(
        "--out",
        type=str,
        default="",
        help="Optional final report path (e.g. outputs/step1_report.md). If omitted, prints to stdout.",
    )

    # íƒœìŠ¤í¬ë³„ ì‚°ì¶œë¬¼ ì €ì¥ ë””ë ‰í† ë¦¬(ê¸°ë³¸ê°’: outputs)
    parser.add_argument(
        "--out-dir",
        type=str,
        default="outputs",
        help="Directory to save per-task outputs (default: outputs).",
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Validate inputs and show configuration without running the crew.",
    )

    parser.add_argument(
        "--auto-revise",
        action="store_true",
        help="Landing Gate íŒì •ì´ LANDING_HOLDì¼ ë•Œ ìë™ìœ¼ë¡œ revisionì„ 1íšŒ ì‹¤í–‰. "
             "LANDING_GOë©´ ë°”ë¡œ final report, LANDING_NOë©´ revision ì—†ì´ ì¢…ë£Œ.",
    )
    parser.add_argument(
        "--revise-no",
        action="store_true",
        help="--auto-reviseì™€ í•¨ê»˜ ì‚¬ìš©. LANDING_NOì¼ ë•Œë„ revisionì„ ì‹œë„. "
             "(ê¸°ë³¸ì ìœ¼ë¡œ NOëŠ” revision ì—†ì´ ì¢…ë£Œë¨)",
    )
    
    # ìš´ì˜ê¸‰ ê°€ë“œë ˆì¼ ì˜µì…˜
    parser.add_argument(
        "--safe-mode",
        action="store_true",
        help="ìš´ì˜ê¸‰ ì•ˆì „ ëª¨ë“œ: context í¬ê¸°ê°€ ì„ê³„ì¹˜ë¥¼ ë„˜ìœ¼ë©´ ìë™ ì¶•ì†Œ. "
             "TPM ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ê°€ë“œë ˆì¼ ì ìš©.",
    )
    
    # í›„ì† ëŒ€í™” ëª¨ë“œ
    parser.add_argument(
        "--chat",
        action="store_true",
        help="ë¦¬í¬íŠ¸ ìƒì„± í›„ í›„ì† ëŒ€í™” ëª¨ë“œ ì‹œì‘. "
             "ë¦¬í¬íŠ¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê±°ë‚˜ ë°˜ë¡ (Claim)ì„ ì œê¸°í•˜ë©´ AIê°€ ë‹µë³€í•©ë‹ˆë‹¤.",
    )

    args = parser.parse_args(argv)

    inputs: Dict[str, Any] = {}

    # 1) JSON íŒŒì¼ ì…ë ¥
    if args.input:
        loaded = _load_inputs_from_json(Path(args.input))
        inputs = {**inputs, **loaded}

    # 2) CLI argsë¡œ ì˜¤ë²„ë¼ì´ë“œ/ë³´ì™„
    cli_map = {
        "idea_one_liner": args.idea,
        "target_customer": args.target,
        "problem_statement": args.problem,
        "current_alternatives": args.alternatives,
        "geo_market": args.geo,
        "business_type": args.type,
        "constraints": args.constraints,
        "success_definition": args.success,
    }
    for k, v in cli_map.items():
        if v:
            inputs[k] = v

    # 2.5) ì„ íƒì  í•„ë“œì— ê¸°ë³¸ê°’ ì ìš©
    for k, default_val in OPTIONAL_FIELDS.items():
        if not inputs.get(k):
            inputs[k] = default_val

    # 3) ê²€ì¦
    try:
        _validate_inputs(inputs)
    except Exception as e:
        print(f"âŒ Input error: {e}\n", file=sys.stderr)
        return 2

    # 4) ì—”ì§„ ì‹¤í–‰
    try:
        return run_gap_foundry_engine(inputs, args)
    except Exception as e:
        print(f"âŒ Execution error: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


def run_gap_foundry_engine(
    inputs: Dict[str, Any], 
    args: argparse.Namespace, 
    custom_run_id: Optional[str] = None,
    progress_callback: Optional[Callable] = None,
) -> int:
    """
    Gap Foundry í•µì‹¬ ì—”ì§„ (JSON/Dict ì…ë ¥ì„ ë°›ì•„ ë¦¬í¬íŠ¸ ìƒì„±)
    
    Args:
        inputs: ì•„ì´ë””ì–´ ì…ë ¥ ë°ì´í„°
        args: ì‹¤í–‰ ì˜µì…˜
        custom_run_id: ì»¤ìŠ¤í…€ ì‹¤í–‰ ID (ì›¹ APIìš©)
        progress_callback: ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°± (task_id, status, progress, step)
    """
    # 1) PreGate: ì…ë ¥ êµ¬ì²´ì„± ì²´í¬
    pregate_result = _pregate_check(inputs)
    
    if not pregate_result.is_valid:
        print("\n" + "=" * 60)
        print("ğŸ”´ LANDING_NO: ê²€ì¦ ë‹¨ìœ„ ì„±ë¦½ ë¶ˆê°€ (ëª¨í˜¸í•¨/ìƒì‹ ìˆ˜ì¤€)")
        print("=" * 60)
        print("\nâŒ ì‹¤íŒ¨ í•­ëª©:")
        for reason in pregate_result.fail_reasons:
            first_line = reason.split('\n')[0]
            print(f"   â€¢ {first_line}")
        
        # PreGate FAIL ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥
        out_dir = Path(args.out_dir)
        run_id = custom_run_id or _generate_run_id(inputs)
        fail_report = _generate_pregate_fail_report(inputs, pregate_result, out_dir, run_id)
        
        report_dir = out_dir / "reports"
        report_dir.mkdir(parents=True, exist_ok=True)
        idea_slug = re.sub(r"[^\wê°€-í£]", "", inputs.get("idea_one_liner", "unknown"))[:15]
        biz_type = inputs.get("business_type", "B2C")
        report_filename = f"{datetime.now().strftime('%Y-%m-%d_%H%M')}_{idea_slug}_{biz_type}_report.md"
        report_path = report_dir / report_filename
        report_path.write_text(fail_report, encoding="utf-8")
        
        print(f"\nğŸ“ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        print("=" * 60)
        return 3  # PreGate FAIL exit code
    
    # 2) 2-stage ì‹¤í–‰ ë° revision-onlyìš© ê¸°ë³¸ê°’ ì¶”ê°€
    inputs.setdefault("previous_positioning_output", "")
    inputs.setdefault("previous_red_team_output", "")
    inputs.setdefault("research_summary", "")
    inputs.setdefault("gap_hypotheses", "")
    inputs.setdefault("landing_gate_verdict", "")

    # 3) Dry-run ëª¨ë“œ
    if args.dry_run:
        print("\n" + "=" * 60)
        print("ğŸ” DRY-RUN MODE")
        print("=" * 60)
        try:
            crew, tracker = Step1CrewFactory().build(show_progress=False)
            print(f"   âœ… ì—ì´ì „íŠ¸ {len(crew.agents)}ê°œ ìƒì„±ë¨")
            print(f"   âœ… íƒœìŠ¤í¬ {len(crew.tasks)}ê°œ ìƒì„±ë¨")
            return 0
        except Exception as e:
            print(f"   âŒ Crew êµ¬ì„± ì‹¤íŒ¨: {e}", file=sys.stderr)
            return 1

    # 4) ì‹¤í–‰ ì¤€ë¹„
    out_dir = Path(args.out_dir)
    run_id = custom_run_id or _generate_run_id(inputs)
    run_started_at = time.time()
    run_started_at_iso = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    stage_times: Dict[str, float] = {}
    
    final_verdict: str = ""
    final_text: str = ""

    # 5) ë©”ì¸ ì›Œí¬í”Œë¡œìš° (Auto-Revise ë˜ëŠ” Standard)
    if args.auto_revise:
        # Pass 1: ë¦¬ì„œì¹˜ + íŒì •
        print("\nğŸ” Pass 1: ë¦¬ì„œì¹˜ + Landing Gate íŒì •...")
        start_time_pass1 = time.time()
        crew_pass1, tracker = Step1CrewFactory().build_without_final_report(
            include_revision=False, show_progress=True, external_callback=progress_callback
        )
        pass1_result = crew_pass1.kickoff(inputs=inputs)
        elapsed_pass1 = time.time() - start_time_pass1
        stage_times["Pass 1 (Research + Gate)"] = elapsed_pass1
        
        run_id_pass1 = f"{run_id}_pass1"
        _save_task_outputs(crew_pass1, out_dir=out_dir, run_id=run_id_pass1)
        _log_usage_metrics(crew_pass1, out_dir=out_dir, run_id=run_id_pass1, elapsed_seconds=elapsed_pass1)
        
        verdict, _ = _extract_verdict_from_crew(crew_pass1, out_dir=out_dir, run_id=run_id_pass1)
        final_verdict = verdict
        final_stage_run_id = run_id_pass1
        
        # Pass 2: Revision (í•„ìš”ì‹œ)
        do_revision = (verdict == "LANDING_HOLD") or (verdict == "LANDING_NO" and args.revise_no)
        if do_revision:
            print(f"\nğŸ”§ Pass 2: Revision ({verdict})...")
            pass1_outputs = _load_pass1_outputs_for_revision(out_dir, run_id_pass1)
            revision_inputs = {**inputs, **pass1_outputs}
            
            start_time_pass2 = time.time()
            crew_pass2, _ = Step1CrewFactory().build_revision_only(show_progress=True, external_callback=progress_callback)
            pass2_result = crew_pass2.kickoff(inputs=revision_inputs)
            elapsed_pass2 = time.time() - start_time_pass2
            stage_times["Pass 2 (Revision)"] = elapsed_pass2
            
            run_id_pass2 = f"{run_id}_pass2"
            _save_task_outputs(crew_pass2, out_dir=out_dir, run_id=run_id_pass2)
            _log_usage_metrics(crew_pass2, out_dir=out_dir, run_id=run_id_pass2, elapsed_seconds=elapsed_pass2)
            
            verdict_v2, _ = _extract_verdict_from_crew(crew_pass2, out_dir=out_dir, run_id=run_id_pass2)
            final_verdict = verdict_v2 if verdict_v2 else verdict
            final_stage_run_id = run_id_pass2

        # Stage B: ë¦¬í¬íŠ¸ ìƒì„±
        print("\nğŸ“ Stage B: ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±...")
        stage_outputs = _load_pass1_outputs_for_revision(out_dir, final_stage_run_id)
        report_inputs = {
            **inputs,
            "landing_gate_verdict": final_verdict,
            **stage_outputs
        }
        start_time_report = time.time()
        crew_report, _ = Step1CrewFactory().build_final_report_only(show_progress=True)
        final_result = crew_report.kickoff(inputs=report_inputs)
        elapsed_report = time.time() - start_time_report
        stage_times["Stage B (Report)"] = elapsed_report
        final_text = str(final_result)
        final_run_id = f"{run_id}_final"
        _save_task_outputs(crew_report, out_dir=out_dir, run_id=final_run_id)
        _log_usage_metrics(crew_report, out_dir=out_dir, run_id=final_run_id, elapsed_seconds=elapsed_report)
    
    else:
        # Standard 2-stage
        print("\nğŸš€ Stage 1: ë¦¬ì„œì¹˜ + Landing Gate íŒì •...")
        start_time = time.time()
        crew_stage1, _ = Step1CrewFactory().build_without_final_report(include_revision=False, show_progress=True)
        stage1_result = crew_stage1.kickoff(inputs=inputs)
        elapsed_time = time.time() - start_time
        stage_times["Stage 1 (Research + Gate)"] = elapsed_time
        
        stage1_run_id = f"{run_id}_stage1"
        _save_task_outputs(crew_stage1, out_dir=out_dir, run_id=stage1_run_id)
        
        verdict, _ = _extract_verdict_from_crew(crew_stage1, out_dir=out_dir, run_id=stage1_run_id)
        final_verdict = verdict
        
        print("\nğŸ“ Stage 2: ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±...")
        stage1_outputs = _load_pass1_outputs_for_revision(out_dir, stage1_run_id)
        report_inputs = {
            **inputs,
            "landing_gate_verdict": verdict,
            "research_summary": stage1_outputs.get("research_summary", ""),
            "gap_hypotheses": stage1_outputs.get("gap_hypotheses", ""),
        }
        crew_stage2, _ = Step1CrewFactory().build_final_report_only(show_progress=True)
        final_result = crew_stage2.kickoff(inputs=report_inputs)
        final_text = str(final_result)
        _save_task_outputs(crew_stage2, out_dir=out_dir, run_id=run_id)

    # 6) ê²°ê³¼ ì •ë¦¬ ë° ì €ì¥
    total_elapsed = time.time() - run_started_at
    run_finished_at_iso = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # Metrics ë¡œë“œ (ë§ˆì§€ë§‰ ì‹¤í–‰ ë‹¨ê³„ ê¸°ì¤€)
    metrics = {}
    try:
        final_metrics_run_id = f"{run_id}_final" if args.auto_revise else run_id
        metrics_path = out_dir / "runs" / final_metrics_run_id / "_usage_metrics.json"
        if metrics_path.exists():
            metrics = json.loads(metrics_path.read_text(encoding="utf-8"))
    except Exception: pass

    report_header = _generate_report_header(
        inputs=inputs, run_id=run_id, args=args,
        run_started_at=run_started_at_iso, run_finished_at=run_finished_at_iso,
        total_elapsed=total_elapsed, stage_times=stage_times, final_verdict=final_verdict
    )
    report_footer = _generate_report_footer(
        metrics=metrics,
        run_started_at=run_started_at_iso,
        run_finished_at=run_finished_at_iso,
        total_elapsed=total_elapsed,
        stage_times=stage_times,
    ) if metrics else ""
    
    # ë³¸ë¬¸ í´ë¦¬ë‹ (ì¤‘ë³µ ì„¹ì…˜ ì œê±° ë“±)
    code_only_headers = [
        r'##\s*â±ï¸\s*ì‹¤í–‰\s*ì •ë³´.*?(?=\n##|\n---|\Z)',
        r'##\s*ğŸ§©\s*ê²€ì¦\s*ëŒ€ìƒ\s*ì•„ì´ë””ì–´.*?(?=\n##|\n---|\Z)',
        r'##\s*ğŸš¦\s*Landing\s*Gate\s*ê²°ê³¼\s*ìš”ì•½.*?(?=\n##|\n---|\Z)',
        r'##\s*ğŸ“Š\s*í† í°/ë¹„ìš©\s*í†µê³„.*?(?=\n##|\n---|\Z)',
    ]
    for pattern in code_only_headers:
        final_text = re.sub(pattern, '', final_text, flags=re.DOTALL)
    
    final_report = report_header + final_text + report_footer
    
    if args.out:
        out_path = Path(args.out)
    else:
        reports_dir = out_dir / "reports"
        reports_dir.mkdir(parents=True, exist_ok=True)
        out_path = reports_dir / f"{run_id}_report.md"
    
    _safe_write_text(out_path, final_report)
    print(f"\nâœ… Final report saved: {out_path}")

    # í›„ì† ëŒ€í™” ëª¨ë“œ
    if args.chat:
        _start_report_chat(final_text, inputs)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())