"""
Gap Foundry API Server

FastAPI ê¸°ë°˜ ì›¹ ì„œë¹„ìŠ¤ ë°±ì—”ë“œ:
- POST /validate: ì•„ì´ë””ì–´ ê²€ì¦ ìš”ì²­ (ë¹„ë™ê¸° ì²˜ë¦¬)
- GET /status/{run_id}: ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ
- GET /report/{run_id}: ì™„ì„±ëœ ë¦¬í¬íŠ¸ ì¡°íšŒ
- GET /stream/{run_id}: SSE ì‹¤ì‹œê°„ ì§„í–‰ ìƒíƒœ ìŠ¤íŠ¸ë¦¼
- POST /pregate: PreGateë§Œ ë¹ ë¥´ê²Œ ì²´í¬ (ë™ê¸°)

Usage:
    uvicorn gap_foundry.api:app --reload --host 0.0.0.0 --port 8000
"""

from fastapi import FastAPI, BackgroundTasks, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, FileResponse
from pydantic import BaseModel, Field
from typing import Dict, Any, Optional, List
from pathlib import Path
from enum import Enum
import uuid
import json
import asyncio
import re
from datetime import datetime

# Gap Foundry ì—”ì§„ ìž„í¬íŠ¸
from gap_foundry.main import (
    run_gap_foundry_engine,
    _pregate_check,
    _generate_run_id,
    PreGateResult,
)

# ============================================================================
# FastAPI App ì„¤ì •
# ============================================================================

app = FastAPI(
    title="Gap Foundry API",
    description="AI-powered Market Validation Engine - ì•„ì´ë””ì–´ì˜ ì´ˆê¸° ê²€ì¦ ê°€ì¹˜ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
)

# CORS ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ë¡œ origin ì„¤ì • ê°€ëŠ¥)
import os
CORS_ORIGINS = os.getenv("CORS_ORIGINS", "http://localhost:3000,http://127.0.0.1:3000").split(",")

app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,  # í™˜ê²½ë³€ìˆ˜: CORS_ORIGINS=https://your-frontend.vercel.app
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================================
# Pydantic ëª¨ë¸
# ============================================================================

class BusinessType(str, Enum):
    B2B = "B2B"
    B2C = "B2C"
    B2B2C = "B2B2C"


class GeoMarket(str, Enum):
    KR = "KR"
    US = "US"
    GLOBAL = "Global"


class ValidationRequest(BaseModel):
    """ì•„ì´ë””ì–´ ê²€ì¦ ìš”ì²­"""
    idea_one_liner: str = Field(..., min_length=5, description="ì•„ì´ë””ì–´ í•œ ì¤„ ìš”ì•½")
    target_customer: str = Field(..., min_length=2, description="íƒ€ê¹ƒ ê³ ê°")
    problem_statement: str = Field(..., min_length=5, description="í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œ")
    current_alternatives: str = Field(..., description="í˜„ìž¬ ëŒ€ì•ˆë“¤")
    geo_market: GeoMarket = Field(default=GeoMarket.KR, description="ëª©í‘œ ì‹œìž¥")
    business_type: BusinessType = Field(default=BusinessType.B2B, description="ë¹„ì¦ˆë‹ˆìŠ¤ ìœ í˜•")
    constraints: Optional[str] = Field(default="íŠ¹ë³„í•œ ì œì•½ ì—†ìŒ", description="ì œì•½ ì¡°ê±´")
    success_definition: Optional[str] = Field(
        default="ê²½ìŸì‚¬ ëŒ€ë¹„ ëª…í™•í•œ ì°¨ë³„ì  ë„ì¶œ", 
        description="ì„±ê³µ ì •ì˜"
    )

    class Config:
        json_schema_extra = {
            "example": {
                "idea_one_liner": "ëŒ€ê¸°ì—… ì¸ì‚¬íŒ€ì„ ìœ„í•œ ì§ì› ì‹¬ë¦¬ ìƒíƒœ ì˜ˆì¸¡ AI ëŒ€ì‹œë³´ë“œ",
                "target_customer": "ì§ì› ìˆ˜ 1,000ëª… ì´ìƒ ëŒ€ê¸°ì—…ì˜ ì¸ì‚¬(HR)íŒ€",
                "problem_statement": "ì¡°ì§ ë‚´ ë²ˆì•„ì›ƒì´ë‚˜ ì´ì§ ì§•í›„ë¥¼ ì‚¬ì „ì— íŒŒì•…í•˜ê¸° ì–´ë µë‹¤",
                "current_alternatives": "ì—° 1~2íšŒ ì§ì› ë§Œì¡±ë„ ì„¤ë¬¸ì´ë‚˜ í‡´ì‚¬ìž ë©´ë‹´ì— ì˜ì¡´",
                "geo_market": "KR",
                "business_type": "B2B"
            }
        }


class JobStatus(str, Enum):
    QUEUED = "queued"
    PREGATE_CHECKING = "pregate_checking"
    PREGATE_FAILED = "pregate_failed"
    RESEARCHING = "researching"
    ANALYZING = "analyzing"
    GENERATING_REPORT = "generating_report"
    COMPLETED = "completed"
    FAILED = "failed"


class ValidationStatus(BaseModel):
    """ê²€ì¦ ìž‘ì—… ìƒíƒœ"""
    run_id: str
    status: JobStatus
    progress: int = Field(default=0, ge=0, le=100, description="ì§„í–‰ë¥  (0-100)")
    current_step: Optional[str] = Field(default=None, description="í˜„ìž¬ ì§„í–‰ ì¤‘ì¸ ë‹¨ê³„")
    verdict: Optional[str] = Field(default=None, description="ìµœì¢… íŒì • (GO/HOLD/NO)")
    created_at: str
    updated_at: Optional[str] = None
    report_url: Optional[str] = None
    error_message: Optional[str] = None


class PreGateRequest(BaseModel):
    """PreGate ë¹ ë¥¸ ì²´í¬ ìš”ì²­"""
    idea_one_liner: str
    target_customer: str
    problem_statement: str
    current_alternatives: Optional[str] = ""


class PreGateResponse(BaseModel):
    """PreGate ì²´í¬ ê²°ê³¼"""
    is_valid: bool
    score: float = Field(description="êµ¬ì²´ì„± ì ìˆ˜ (0.0-1.0)")
    fail_reasons: List[str]
    warnings: List[str]
    suggestions: List[str] = Field(default_factory=list, description="ê°œì„  ì œì•ˆ")


class ReportResponse(BaseModel):
    """ë¦¬í¬íŠ¸ ì‘ë‹µ"""
    run_id: str
    verdict: str
    report_markdown: str
    report_html: Optional[str] = None
    created_at: str


# ============================================================================
# ìƒíƒœ ì €ìž¥ì†Œ ë° ì˜ì†ì„± (ì„œë²„ ìž¬ì‹œìž‘ ëŒ€ì‘)
# ============================================================================

JOBS_FILE = Path("outputs/jobs.json")
jobs: Dict[str, Dict[str, Any]] = {}
job_logs: Dict[str, List[str]] = {}  # SSEìš© ë¡œê·¸


def _save_jobs():
    """ìž‘ì—… ìƒíƒœë¥¼ íŒŒì¼ì— ì €ìž¥"""
    try:
        JOBS_FILE.parent.mkdir(parents=True, exist_ok=True)
        # JSON ì§ë ¬í™”ê°€ ì•ˆ ë˜ëŠ” ê°ì²´ ë°©ì§€
        serializable_jobs = {}
        for k, v in jobs.items():
            serializable_jobs[k] = v.copy()
            # í˜¹ì‹œ ëª¨ë¥¼ ë¹„ì§ë ¬í™” ë°ì´í„° ì œê±°
        
        with open(JOBS_FILE, "w", encoding="utf-8") as f:
            json.dump(serializable_jobs, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[ERROR] Failed to save jobs: {e}")


def _load_jobs():
    """íŒŒì¼ì—ì„œ ìž‘ì—… ìƒíƒœ ë¡œë“œ"""
    global jobs
    if JOBS_FILE.exists():
        try:
            with open(JOBS_FILE, "r", encoding="utf-8") as f:
                loaded = json.load(f)
                # ì„œë²„ ìž¬ì‹œìž‘ ì‹œ ì§„í–‰ ì¤‘ì´ë˜ ìž‘ì—…ì€ FAILEDë¡œ í‘œì‹œ (í”„ë¡œì„¸ìŠ¤ê°€ ì£½ì—ˆìœ¼ë¯€ë¡œ)
                for jid, jdata in loaded.items():
                    if jdata["status"] not in [
                        JobStatus.COMPLETED.value, 
                        JobStatus.FAILED.value, 
                        JobStatus.PREGATE_FAILED.value
                    ]:
                        jdata["status"] = JobStatus.FAILED.value
                        jdata["error_message"] = "ì„œë²„ ìž¬ì‹œìž‘ìœ¼ë¡œ ì¸í•´ ìž‘ì—…ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                jobs.update(loaded)
        except Exception as e:
            print(f"[ERROR] Failed to load jobs: {e}")


@app.on_event("startup")
async def startup_event():
    _load_jobs()


def _update_job_status(
    run_id: str, 
    status: JobStatus, 
    progress: int = 0,
    current_step: str = None,
    verdict: str = None,
    error_message: str = None,
    report_path: str = None,
):
    """ìž‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸ (ë‚´ë¶€ìš©)"""
    if run_id not in jobs:
        return
    
    jobs[run_id].update({
        "status": status.value,
        "progress": progress,
        "current_step": current_step,
        "updated_at": datetime.now().isoformat(),
    })
    
    if verdict:
        jobs[run_id]["verdict"] = verdict
    if error_message:
        jobs[run_id]["error_message"] = error_message
    if report_path:
        jobs[run_id]["report_path"] = report_path
    
    # SSE ë¡œê·¸ ì¶”ê°€
    log_msg = f"[{progress}%] {current_step or status.value}"
    if run_id not in job_logs:
        job_logs[run_id] = []
    job_logs[run_id].append(log_msg)

    # íŒŒì¼ì— ì €ìž¥
    _save_jobs()


# ============================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "name": "Gap Foundry API",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs",
    }


@app.post("/pregate", response_model=PreGateResponse)
async def check_pregate(request: PreGateRequest):
    """
    PreGate ë¹ ë¥¸ ì²´í¬ (ë™ê¸°)
    
    LLMì„ í˜¸ì¶œí•˜ì§€ ì•Šê³  ìž…ë ¥ì˜ êµ¬ì²´ì„±ë§Œ ë¹ ë¥´ê²Œ ê²€ì‚¬í•©ë‹ˆë‹¤.
    ì‹¤ì‹œê°„ í”¼ë“œë°±ì— ì í•©í•©ë‹ˆë‹¤.
    """
    inputs = {
        "idea_one_liner": request.idea_one_liner,
        "target_customer": request.target_customer,
        "problem_statement": request.problem_statement,
        "current_alternatives": request.current_alternatives or "",
    }
    
    result: PreGateResult = _pregate_check(inputs)
    
    # ê°œì„  ì œì•ˆ ìƒì„±
    suggestions = []
    if not result.is_valid:
        if any("íƒ€ê¹ƒ" in r for r in result.fail_reasons):
            suggestions.append("íƒ€ê¹ƒì„ ë” êµ¬ì²´ì ìœ¼ë¡œ: 'ëª¨ë“  ì‚¬ëžŒ' â†’ 'ì•¼ê·¼ì´ ìž¦ì€ 30ëŒ€ ì§ìž¥ì¸'")
        if any("ë¬¸ì œ" in r or "ìƒì‹" in r for r in result.fail_reasons):
            suggestions.append("ë¬¸ì œë¥¼ êµ¬ì²´ì  ìƒí™©ìœ¼ë¡œ: 'ê±´ê°•ì´ ì¤‘ìš”í•˜ë‹¤' â†’ 'ë°¤ 10ì‹œ ì´í›„ ê³¼ì‹ì„ í›„íšŒí•œë‹¤'")
        if any("í–‰ë™" in r for r in result.fail_reasons):
            suggestions.append("êµ¬ì²´ì  í–‰ë™ ì¶”ê°€: 'ë•ëŠ” ì•±' â†’ 'ì„­ì·¨ ì¹¼ë¡œë¦¬ë¥¼ ìžë™ìœ¼ë¡œ ê¸°ë¡í•˜ëŠ” ì•±'")
    
    return PreGateResponse(
        is_valid=result.is_valid,
        score=result.score,
        fail_reasons=result.fail_reasons,
        warnings=result.warnings,
        suggestions=suggestions,
    )


@app.post("/validate", response_model=ValidationStatus)
async def validate_idea(request: ValidationRequest, background_tasks: BackgroundTasks):
    """
    ì•„ì´ë””ì–´ ê²€ì¦ ìš”ì²­ (ë¹„ë™ê¸°)
    
    CrewAI ê¸°ë°˜ ì „ì²´ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    - ê²½ìŸì‚¬ ë¦¬ì„œì¹˜
    - ì±„ë„/VP ë¶„ì„
    - ë¹ˆí‹ˆ ë°œêµ´
    - Red Team ê²€í† 
    - ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
    
    ì†Œìš” ì‹œê°„: ì•½ 10-15ë¶„
    """
    inputs = request.model_dump()
    run_id = f"web_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:6]}"
    
    # ìž‘ì—… ì´ˆê¸°í™”
    jobs[run_id] = {
        "status": JobStatus.QUEUED.value,
        "progress": 0,
        "current_step": "ëŒ€ê¸° ì¤‘",
        "created_at": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat(),
        "inputs": inputs,
        "verdict": None,
        "report_path": None,
        "error_message": None,
    }
    job_logs[run_id] = []
    
    # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
    background_tasks.add_task(run_validation_job, run_id, inputs)
    
    return ValidationStatus(
        run_id=run_id,
        status=JobStatus.QUEUED,
        progress=0,
        current_step="ìž‘ì—…ì´ íì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤",
        created_at=jobs[run_id]["created_at"],
    )


@app.get("/status/{run_id}", response_model=ValidationStatus)
async def get_status(run_id: str):
    """ìž‘ì—… ìƒíƒœ ì¡°íšŒ"""
    if run_id not in jobs:
        raise HTTPException(status_code=404, detail=f"Job not found: {run_id}")
    
    job = jobs[run_id]
    
    return ValidationStatus(
        run_id=run_id,
        status=JobStatus(job["status"]),
        progress=job.get("progress", 0),
        current_step=job.get("current_step"),
        verdict=job.get("verdict"),
        created_at=job["created_at"],
        updated_at=job.get("updated_at"),
        report_url=f"/report/{run_id}" if job.get("report_path") else None,
        error_message=job.get("error_message"),
    )


@app.get("/stream/{run_id}")
async def stream_progress(run_id: str):
    """
    SSE (Server-Sent Events) ì‹¤ì‹œê°„ ì§„í–‰ ìƒíƒœ ìŠ¤íŠ¸ë¦¼
    
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ EventSourceë¡œ ì—°ê²°í•˜ì—¬ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ë°›ìŠµë‹ˆë‹¤.
    """
    if run_id not in jobs:
        raise HTTPException(status_code=404, detail=f"Job not found: {run_id}")
    
    async def event_generator():
        last_log_index = 0
        
        while True:
            if run_id not in jobs:
                break
            
            job = jobs[run_id]
            
            # ìƒˆ ë¡œê·¸ ì „ì†¡
            logs = job_logs.get(run_id, [])
            for i in range(last_log_index, len(logs)):
                yield f"data: {json.dumps({'type': 'log', 'message': logs[i]})}\n\n"
            last_log_index = len(logs)
            
            # ìƒíƒœ ì „ì†¡
            status_data = {
                "type": "status",
                "status": job["status"],
                "progress": job.get("progress", 0),
                "current_step": job.get("current_step"),
                "verdict": job.get("verdict"),
            }
            yield f"data: {json.dumps(status_data)}\n\n"
            
            # ì™„ë£Œ/ì‹¤íŒ¨ ì‹œ ì¢…ë£Œ
            if job["status"] in [JobStatus.COMPLETED.value, JobStatus.FAILED.value, JobStatus.PREGATE_FAILED.value]:
                yield f"data: {json.dumps({'type': 'done', 'status': job['status']})}\n\n"
                break
            
            await asyncio.sleep(2)  # 2ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        },
    )


@app.get("/report/{run_id}")
async def get_report(run_id: str):
    """ì™„ì„±ëœ ë¦¬í¬íŠ¸ ì¡°íšŒ (Markdown)"""
    if run_id not in jobs:
        raise HTTPException(status_code=404, detail=f"Job not found: {run_id}")
    
    job = jobs[run_id]
    
    if job["status"] != JobStatus.COMPLETED.value:
        raise HTTPException(
            status_code=400, 
            detail=f"Report not ready. Current status: {job['status']}"
        )
    
    report_path = job.get("report_path")
    if not report_path or not Path(report_path).exists():
        # ëŒ€ì²´ ê²½ë¡œ ì‹œë„
        reports_dir = Path("outputs/reports")
        matching = list(reports_dir.glob(f"*{run_id}*_report.md"))
        if matching:
            report_path = str(matching[0])
        else:
            raise HTTPException(status_code=404, detail="Report file not found")
    
    report_content = Path(report_path).read_text(encoding="utf-8")
    
    # Verdict ì¶”ì¶œ
    verdict_match = re.search(r"(LANDING_GO|LANDING_HOLD|LANDING_NO)", report_content)
    verdict = verdict_match.group(1) if verdict_match else "UNKNOWN"
    
    return ReportResponse(
        run_id=run_id,
        verdict=verdict,
        report_markdown=report_content,
        created_at=job["created_at"],
    )


@app.get("/report/{run_id}/download")
async def download_report(run_id: str):
    """ë¦¬í¬íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    if run_id not in jobs:
        raise HTTPException(status_code=404, detail=f"Job not found: {run_id}")
    
    job = jobs[run_id]
    report_path = job.get("report_path")
    
    if not report_path or not Path(report_path).exists():
        reports_dir = Path("outputs/reports")
        matching = list(reports_dir.glob(f"*{run_id}*_report.md"))
        if matching:
            report_path = str(matching[0])
        else:
            raise HTTPException(status_code=404, detail="Report file not found")
    
    return FileResponse(
        path=report_path,
        filename=Path(report_path).name,
        media_type="text/markdown",
    )


@app.get("/jobs")
async def list_jobs(limit: int = 20):
    """ìµœê·¼ ìž‘ì—… ëª©ë¡ ì¡°íšŒ"""
    sorted_jobs = sorted(
        jobs.items(),
        key=lambda x: x[1].get("created_at", ""),
        reverse=True
    )[:limit]
    
    return [
        {
            "run_id": run_id,
            "status": job["status"],
            "verdict": job.get("verdict"),
            "created_at": job["created_at"],
            "idea_preview": job.get("inputs", {}).get("idea_one_liner", "")[:50],
        }
        for run_id, job in sorted_jobs
    ]


# ============================================================================
# ë°±ê·¸ë¼ìš´ë“œ ìž‘ì—… ì‹¤í–‰
# ============================================================================

def run_validation_job(run_id: str, inputs: Dict[str, Any]):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê²€ì¦ ìž‘ì—… ì‹¤í–‰
    
    main.pyì˜ run_gap_foundry_engineì„ í˜¸ì¶œí•˜ë©°,
    ì§„í–‰ ìƒíƒœë¥¼ jobs dictì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    import threading
    import time as time_module
    
    # ì§„í–‰ë¥  ì¶”ì •ì„ ìœ„í•œ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ
    def monitor_progress():
        """outputs/runs í´ë”ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì§„í–‰ë¥  ì¶”ì • (ì„¸ë¶€ ë‹¨ìœ„)"""
        
        # 12ë‹¨ê³„ Ã— ì„¸ë¶€ ì§„í–‰ë¥  (ì‹œìž‘%, ì™„ë£Œ%, ë‹¨ê³„ëª…, ìƒì„¸)
        stage_details = {
            "01_": {
                "base": 8, "complete": 15, 
                "name": "ðŸ” ê²½ìŸì‚¬ ë°œêµ´", 
                "steps": ["ê²€ìƒ‰ ì‹œìž‘", "ê²°ê³¼ ìˆ˜ì§‘ ì¤‘", "í›„ë³´ ëª©ë¡ ìž‘ì„±"]
            },
            "02_": {
                "base": 16, "complete": 22,
                "name": "ðŸ“Š ê²½ìŸì‚¬ ì••ì¶•",
                "steps": ["ì¤‘ìš”ë„ í‰ê°€", "ìƒìœ„ ê²½ìŸì‚¬ ì„ ë³„", "ì••ì¶• ì™„ë£Œ"]
            },
            "03_": {
                "base": 23, "complete": 32,
                "name": "ðŸŒ ì±„ë„ ë¶„ì„",
                "steps": ["ì›¹ì‚¬ì´íŠ¸ ìŠ¤í¬ëž˜í•‘", "ì½˜í…ì¸  ì¶”ì¶œ", "ì±„ë„ ì •ë³´ ì •ë¦¬"]
            },
            "04_": {
                "base": 33, "complete": 42,
                "name": "ðŸ’Ž ê°€ì¹˜ì œì•ˆ ì¶”ì¶œ",
                "steps": ["Hero ì¹´í”¼ ë¶„ì„", "USP ì‹ë³„", "VP ì •ë¦¬ ì™„ë£Œ"]
            },
            "05_": {
                "base": 43, "complete": 50,
                "name": "ðŸ“ ì±„ë„/VP ìš”ì•½",
                "steps": ["ë°ì´í„° í†µí•©", "ìš”ì•½ ìƒì„±"]
            },
            "06_": {
                "base": 51, "complete": 60,
                "name": "ðŸ•³ï¸ ë¹ˆí‹ˆ ë°œêµ´",
                "steps": ["Gap ê°€ì„¤ ìƒì„±", "ê²€ì¦ ì‹ í˜¸ ë„ì¶œ", "ë¹ˆí‹ˆ ëª©ë¡ ì™„ì„±"]
            },
            "07_": {
                "base": 61, "complete": 68,
                "name": "ðŸ“‹ ë¦¬ì„œì¹˜ ìš”ì•½",
                "steps": ["ì „ì²´ ë¦¬ì„œì¹˜ í†µí•©", "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬"]
            },
            "08_": {
                "base": 69, "complete": 76,
                "name": "ðŸŽ¯ POV/í¬ì§€ì…”ë‹",
                "steps": ["í¬ì§€ì…”ë‹ ì„¤ê³„", "ë©”ì‹œì§€ í”„ë ˆì´ë°", "POV ì™„ì„±"]
            },
            "09_": {
                "base": 77, "complete": 84,
                "name": "ðŸ”´ Red Team ê²€í† ",
                "steps": ["Q0-Q5 í‰ê°€", "ì ìˆ˜ ê³„ì‚°", "1ì°¨ íŒì •"]
            },
            "10_": {
                "base": 85, "complete": 88,
                "name": "âœï¸ í¬ì§€ì…”ë‹ ìˆ˜ì •",
                "steps": ["í”¼ë“œë°± ë°˜ì˜", "ìˆ˜ì • ì™„ë£Œ"]
            },
            "11_": {
                "base": 89, "complete": 92,
                "name": "ðŸ”´ Red Team ìž¬ê²€í† ",
                "steps": ["ìµœì¢… ê²€í† ", "VERDICT ê²°ì •"]
            },
            "12_": {
                "base": 93, "complete": 98,
                "name": "ðŸ“„ ë¦¬í¬íŠ¸ ìƒì„±",
                "steps": ["ë¦¬í¬íŠ¸ ìž‘ì„±", "í—¤ë”/í‘¸í„° ì‚½ìž…", "íŒŒì¼ ì €ìž¥"]
            },
        }
        
        last_progress = 0
        
        # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (ìƒëŒ€ ê²½ë¡œ ë¬¸ì œ í•´ê²°)
        base_dir = Path(__file__).parent.parent.parent / "outputs" / "runs"
        
        while run_id in jobs and jobs[run_id]["status"] not in ["completed", "failed", "pregate_failed"]:
            # pass1 ë˜ëŠ” stage1 í´ë” í™•ì¸
            for suffix in ["_pass1", "_stage1", ""]:
                run_dir = base_dir / f"{run_id}{suffix}"
                if run_dir.exists():
                    files = list(run_dir.glob("*.md"))
                    dirs = list(run_dir.glob("*_"))  # ì§„í–‰ ì¤‘ì¸ í´ë” (ëì´ _)
                    all_items = list(run_dir.iterdir())
                    
                    current_progress = 15  # ê¸°ë³¸ê°’: ë¦¬ì„œì¹˜ ì‹œìž‘
                    current_step = "ðŸ” ë¦¬ì„œì¹˜ ì‹œìž‘..."
                    
                    # ì™„ë£Œëœ íŒŒì¼ ê¸°ì¤€ ì§„í–‰ë¥ 
                    for f in files:
                        for prefix, details in stage_details.items():
                            if f.name.startswith(prefix):
                                if details["complete"] > current_progress:
                                    current_progress = details["complete"]
                                    current_step = f"{details['name']} âœ… ì™„ë£Œ"
                    
                    # ì§„í–‰ ì¤‘ì¸ í´ë” ì²´í¬ (ë” ì„¸ë¶€ì ì¸ ì§„í–‰ë¥ )
                    for d in all_items:
                        if d.is_dir():
                            for prefix, details in stage_details.items():
                                if d.name.startswith(prefix):
                                    # í´ë”ê°€ ìžˆìœ¼ë©´ í•´ë‹¹ ë‹¨ê³„ ì§„í–‰ ì¤‘
                                    in_progress = details["base"] + (details["complete"] - details["base"]) // 2
                                    if in_progress > current_progress:
                                        current_progress = in_progress
                                        step_idx = min(1, len(details["steps"]) - 1)
                                        current_step = f"{details['name']} - {details['steps'][step_idx]}"
                    
                    # íŒŒì¼ ê°œìˆ˜ë¡œ ì„¸ë¶€ ì§„í–‰ë¥  ì¡°ì •
                    file_count = len(files)
                    if file_count > 0:
                        # íŒŒì¼ 1ê°œë‹¹ ì•½ 7-8% ì§„í–‰
                        file_based_progress = 15 + (file_count * 7)
                        if file_based_progress > current_progress:
                            current_progress = min(file_based_progress, 95)
                    
                    # ìƒíƒœ ì—…ë°ì´íŠ¸ (ë³€í™”ê°€ ìžˆì„ ë•Œë§Œ)
                    if current_progress > last_progress:
                        last_progress = current_progress
                        
                        if current_progress < 50:
                            status = JobStatus.RESEARCHING
                        elif current_progress < 85:
                            status = JobStatus.ANALYZING
                        else:
                            status = JobStatus.GENERATING_REPORT
                        
                        _update_job_status(run_id, status, current_progress, current_step)
                        # ë¡œê·¸ëŠ” _update_job_status ë‚´ì—ì„œ ìžë™ ì¶”ê°€ë¨
                    break
            
            time_module.sleep(2)  # 2ì´ˆë§ˆë‹¤ ì²´í¬ (ë” ë¹ ë¥´ê²Œ)
    
    try:
        # PreGate ì²´í¬
        _update_job_status(run_id, JobStatus.PREGATE_CHECKING, 5, "ìž…ë ¥ êµ¬ì²´ì„± ê²€ì‚¬ ì¤‘...")
        
        pregate_result = _pregate_check(inputs)
        
        if not pregate_result.is_valid:
            _update_job_status(
                run_id, 
                JobStatus.PREGATE_FAILED, 
                100,
                "ìž…ë ¥ì´ ë„ˆë¬´ ëª¨í˜¸í•©ë‹ˆë‹¤",
                verdict="LANDING_NO",
                error_message="; ".join(pregate_result.fail_reasons),
            )
            return
        
        # ë¦¬ì„œì¹˜ ë‹¨ê³„ ì‹œìž‘ (ì‹¤ì œ ì§„í–‰ë¥ ì€ CrewAI ì½œë°±ì—ì„œ ì—…ë°ì´íŠ¸ë¨)
        _update_job_status(run_id, JobStatus.RESEARCHING, 5, "ë¦¬ì„œì¹˜ ì¤€ë¹„ ì¤‘...")
        
        # ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œìž‘
        monitor_thread = threading.Thread(target=monitor_progress, daemon=True)
        monitor_thread.start()
        
        # Args ê°ì²´ ìƒì„± (main.py í˜¸í™˜)
        class WebArgs:
            def __init__(self):
                self.out_dir = "outputs"
                self.auto_revise = True
                self.revise_no = False
                self.safe_mode = True
                self.chat = False
                self.out = ""
                self.dry_run = False
        
        args = WebArgs()
        
        # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°± (CrewAI ì½œë°±ê³¼ ì—°ê²°)
        # ì§„í–‰ë¥  ë²”ìœ„: PreGate(0~5%) â†’ íƒœìŠ¤í¬ë“¤(5~95%) â†’ ë¦¬í¬íŠ¸(95~100%)
        def progress_callback(task_id: str, status: str, progress: int, step: str):
            """íƒœìŠ¤í¬ë³„ ì§„í–‰ ìƒíƒœë¥¼ API jobs dictì— ì—…ë°ì´íŠ¸"""
            # ì§„í–‰ë¥ ì— ë”°ë¼ ìƒíƒœ ê²°ì •
            if progress < 50:
                job_status = JobStatus.RESEARCHING  # 5~50%: ë¦¬ì„œì¹˜ ì¤‘
            elif progress < 85:
                job_status = JobStatus.ANALYZING    # 50~85%: ë¶„ì„ ì¤‘
            else:
                job_status = JobStatus.GENERATING_REPORT  # 85~100%: ë¦¬í¬íŠ¸ ìƒì„±
            
            _update_job_status(run_id, job_status, progress, step)
            # ë¡œê·¸ëŠ” _update_job_status ë‚´ì—ì„œ ìžë™ ì¶”ê°€ë¨
        
        # ì—”ì§„ ì‹¤í–‰ (ì½œë°± ì „ë‹¬)
        exit_code = run_gap_foundry_engine(inputs, args, custom_run_id=run_id, progress_callback=progress_callback)
        
        if exit_code == 0:
            # ì„±ê³µ - ë¦¬í¬íŠ¸ ê²½ë¡œ ì°¾ê¸°
            reports_dir = Path("outputs/reports")
            matching = list(reports_dir.glob(f"*{run_id}*_report.md"))
            report_path = str(matching[0]) if matching else None
            
            # Verdict ì¶”ì¶œ
            verdict = "UNKNOWN"
            if report_path and Path(report_path).exists():
                content = Path(report_path).read_text(encoding="utf-8")
                match = re.search(r"(LANDING_GO|LANDING_HOLD|LANDING_NO)", content)
                if match:
                    verdict = match.group(1)
            
            _update_job_status(
                run_id, 
                JobStatus.COMPLETED, 
                100,
                "ê²€ì¦ ì™„ë£Œ!",
                verdict=verdict,
                report_path=report_path,
            )
        
        elif exit_code == 3:
            # PreGate ì‹¤íŒ¨ (ì´ë¯¸ ì²˜ë¦¬ë¨, ì—¬ê¸° ë„ë‹¬ ì•ˆ í•¨)
            _update_job_status(
                run_id,
                JobStatus.PREGATE_FAILED,
                100,
                "ìž…ë ¥ êµ¬ì²´í™” í•„ìš”",
                verdict="LANDING_NO",
            )
        
        else:
            # ê¸°íƒ€ ì˜¤ë¥˜
            _update_job_status(
                run_id,
                JobStatus.FAILED,
                100,
                f"ì‹¤í–‰ ì˜¤ë¥˜ (exit code: {exit_code})",
                error_message=f"Engine returned exit code {exit_code}",
            )
    
    except Exception as e:
        import traceback
        _update_job_status(
            run_id,
            JobStatus.FAILED,
            100,
            "ì‹œìŠ¤í…œ ì˜¤ë¥˜",
            error_message=str(e),
        )
        print(f"[ERROR] Job {run_id}: {traceback.format_exc()}")


# ============================================================================
# ì„œë²„ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
