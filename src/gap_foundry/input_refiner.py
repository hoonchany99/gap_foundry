"""
ì…ë ¥ êµ¬ì²´í™” ëª¨ë“ˆ (Input Refiner) - Interview Style

í•µì‹¬ ì² í•™:
- "í¼ì„ ì±„ìš°ëŠ” ë´‡"ì´ ì•„ë‹ˆë¼ "ì•„ì´ë””ì–´ë¥¼ ì´í•´í•˜ë ¤ëŠ” ë™ë£Œ"
- ì§ˆë¬¸ì´ ì•„ë‹ˆë¼ "í•´ì„ ì œì•ˆ"
- ì¢…ë£Œ ì‹œì ì€ ì‚¬ìš©ìê°€ ê²°ì •

2-Phase êµ¬ì¡°:
- Phase A (Exploration): ì•„ì´ë””ì–´ ì´í•´ ì¤‘ì‹¬, ë§¥ë½/ê°ì •/ê³„ê¸° íƒìƒ‰
- Phase B (Structuring): ì´í•´í•œ ë‚´ìš©ì„ êµ¬ì¡°í™”, í™•ì¸/ë³´ì™„

ì‚¬ìš©ë²•:
    from gap_foundry.input_refiner import refine_inputs
    result = refine_inputs()
    inputs = result["inputs"]
"""
from __future__ import annotations

import json
import os
import re
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

from crewai import LLM


# ============================================================================
# ì„¤ì •
# ============================================================================

DEFAULT_FAST_MODEL = "gpt-4.1-mini"
DEFAULT_MAIN_MODEL = "gpt-4.1"

# ìµœì¢… OUTPUTì— í•„ìš”í•œ í•„ë“œ (ë‚´ë¶€ìš©, ì‚¬ìš©ìì—ê²Œ ë…¸ì¶œ ì•ˆ í•¨)
# Note: constraints, success_definitionì€ ì‹œì¥ ê²€ì¦ í•µì‹¬ì´ ì•„ë‹ˆë¯€ë¡œ ì œì™¸
REQUIRED_FIELDS = [
    "idea_one_liner",
    "target_customer",
    "problem_statement",
    "current_alternatives",
    "geo_market",
    "business_type",
]

# í•„ë“œë³„ ê¸°ë³¸ê°’ (ë§ˆì§€ë§‰ì— ëˆ„ë½ëœ ê²½ìš°)
DEFAULT_VALUES = {
    "geo_market": "KR",
    "business_type": "B2C",
}


# ============================================================================
# ëŠ¥ë™ì  í˜¸ê¸°ì‹¬ ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸
# ============================================================================

CURIOSITY_PROMPT = """í˜„ì¬ ì•„ì´ë””ì–´ ì´í•´ ìƒíƒœë¥¼ ë³´ê³ ,
ë‹¤ìŒ ì¤‘ ê°€ì¥ ì¤‘ìš”í•œ 'í•˜ë‚˜'ë¥¼ ë” ì´í•´í•˜ê¸° ìœ„í•œ ì§ˆë¬¸ ì˜ë„ë¥¼ ê³ ë¥´ì„¸ìš”.

ìš°ì„ ìˆœìœ„:
1. ì™œ ì´ ë¬¸ì œê°€ ìƒê²¼ëŠ”ì§€ (ê³„ê¸°/ê²½í—˜)
2. ì‹¤ì œë¡œ ê°€ì¥ ë¶ˆí¸í•œ ìˆœê°„ (í–‰ë™/ìƒí™©)
3. ì´ ë¬¸ì œë¥¼ ê°€ì¥ ì ˆì‹¤íˆ ëŠë¼ëŠ” ì‚¬ëŒ
4. ì§€ê¸ˆ ì“°ëŠ” ëŒ€ì•ˆì˜ êµ¬ì²´ì  ë¶ˆë§Œ
5. ì™œ ì§€ê¸ˆ ì´ ë¬¸ì œì¸ì§€ (íƒ€ì´ë°)

ì¶œë ¥ í˜•ì‹ (JSONë§Œ, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€):
- focus: ì„ íƒí•œ ìš°ì„ ìˆœìœ„ í•­ëª©
- intent: ì´ê±¸ ë” ì´í•´í•˜ë©´ ì „ì²´ ì•„ì´ë””ì–´ê°€ ëª…í™•í•´ì§€ëŠ” ì´ìœ  (1ë¬¸ì¥)
- suggested_angle: í•´ì„ ì œì•ˆ í˜•íƒœì˜ ì§ˆë¬¸ ë°©í–¥ (ìì—°ì–´, ë¬¼ìŒí‘œ ê¸ˆì§€)"""


# ============================================================================
# Phase A: Exploration (ì´í•´ ì¤‘ì‹¬) í”„ë¡¬í”„íŠ¸
# ============================================================================

EXPLORATION_PROMPT = """ë‹¹ì‹ ì€ ì°½ì—… ì•„ì´ë””ì–´ë¥¼ ì´í•´í•˜ë ¤ëŠ” ë™ë£Œì…ë‹ˆë‹¤.
í‰ê°€í•˜ê±°ë‚˜ íŒë‹¨í•˜ì§€ ë§ê³ , ë¨¼ì € ì´í•´í•˜ì„¸ìš”.

[ë‹¹ì‹ ì˜ ì—­í• ]
- ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ "ì´í•´"í•˜ë ¤ê³  ë…¸ë ¥í•©ë‹ˆë‹¤
- ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ì±„ìš°ë ¤ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í•©ë‹ˆë‹¤
- ì§ˆë¬¸ë³´ë‹¤ëŠ” "í•´ì„ ì œì•ˆ"ì„ í•©ë‹ˆë‹¤

[íƒìƒ‰í•  ê²ƒë“¤] (ìˆœì„œ/ì™„ì„±ë„ ê°•ì œ X)
- ì™œ ì´ ì•„ì´ë””ì–´ê°€ ë– ì˜¬ëëŠ”ì§€ (ê³„ê¸°, ê²½í—˜)
- ì–´ë–¤ ìƒí™©ì—ì„œ ì´ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ”ì§€
- ëˆ„ê°€ ì´ ë¬¸ì œë¥¼ ê°€ì¥ í¬ê²Œ ëŠë¼ëŠ”ì§€
- ì§€ê¸ˆì€ ì–´ë–»ê²Œ í•´ê²°í•˜ê³  ìˆëŠ”ì§€
- ê°ì •: ì§œì¦, ì‹œê°„ ë‚­ë¹„, ë¶ˆì•ˆ ë“±

[ëŒ€í™” ìŠ¤íƒ€ì¼]
- ì¹œê·¼í•˜ê³  í˜¸ê¸°ì‹¬ ì–´ë¦° í†¤
- í•œ ë²ˆì— 1~2ê°€ì§€ë§Œ ë¬¼ì–´ë³´ê¸°
- "~ì¸ ê²ƒ ê°™ì•„ìš”. ë§ë‚˜ìš”?" í˜•íƒœë¡œ í•´ì„ ì œì•ˆ
- ì´ëª¨ì§€ ì ë‹¹íˆ ì‚¬ìš© OK

[ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ]
- JSON ì¶œë ¥
- "íƒ€ê¹ƒ ê³ ê°ì´ ëˆ„êµ¬ì¸ê°€ìš”?" ê°™ì€ ì§ì ‘ì  í•„ë“œ ì§ˆë¬¸
- ì²´í¬ë¦¬ìŠ¤íŠ¸ ì–¸ê¸‰
- í‰ê°€/íŒë‹¨

[í˜„ì¬ê¹Œì§€ ì´í•´í•œ ë‚´ìš©]
{current_understanding}

[ëŒ€í™” ê¸°ë¡]
{conversation_summary}

ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ë§ì— ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•˜ì„¸ìš”."""


# ============================================================================
# Phase B: Structuring (êµ¬ì¡°í™”) í”„ë¡¬í”„íŠ¸
# ============================================================================

STRUCTURING_PROMPT = """ë‹¹ì‹ ì€ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë©° ì•„ì´ë””ì–´ë¥¼ ì´í•´í•œ ë™ë£Œì…ë‹ˆë‹¤.
ì´ì œ ì´í•´í•œ ë‚´ìš©ì„ ì •ë¦¬í•´ì„œ í™•ì¸ë°›ì„ ì°¨ë¡€ì…ë‹ˆë‹¤.

[í˜„ì¬ê¹Œì§€ ì´í•´í•œ ë‚´ìš©]
{current_understanding}

[ì•„ì§ ëª…í™•í•˜ì§€ ì•Šì€ ë¶€ë¶„]
{unclear_parts}

[ë‹¹ì‹ ì˜ ì—­í• ]
1. ì´í•´í•œ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•´ì„œ ë³´ì—¬ì£¼ê¸°
2. ëª…í™•í•˜ì§€ ì•Šì€ ë¶€ë¶„ì€ "ì¶”ì •"ìœ¼ë¡œ í‘œì‹œí•˜ê³ , ë§ëŠ”ì§€ ë¬¼ì–´ë³´ê¸°
3. ì‚¬ìš©ìê°€ OKí•˜ë©´ â†’ ì‹œì¥ ê²€ì¦ ì§„í–‰ ì œì•ˆ

[ì‘ë‹µ í˜•ì‹]
ìì—°ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”. JSON ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

ì˜ˆì‹œ:
"ì§€ê¸ˆê¹Œì§€ ì´ì•¼ê¸° ì •ë¦¬í•´ë³¼ê²Œìš” ğŸ“‹

**ì•„ì´ë””ì–´**: ...
**ì´ ë¬¸ì œë¥¼ ê°€ì¥ í¬ê²Œ ëŠë¼ëŠ” ì‚¬ëŒ**: ...
**í•µì‹¬ ë¶ˆí¸í•¨**: ...
**ì§€ê¸ˆ ëŒ€ì•ˆ**: ... (ì¶”ì •)

ì´ ì •ë„ë©´ ì‹œì¥ ê²€ì¦ì„ ì‹œì‘í•  ìˆ˜ ìˆì–´ìš”!
í˜¹ì‹œ ìˆ˜ì •í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”.
ê´œì°®ìœ¼ë©´ 'done' ë˜ëŠ” 'ì‹œì‘'ì´ë¼ê³  í•´ì£¼ì„¸ìš” ğŸ˜Š"

[ëŒ€í™” ê¸°ë¡]
{conversation_summary}"""


# ============================================================================
# ë‚´ë¶€ ìƒíƒœ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ (ì‚¬ìš©ìì—ê²Œ ë…¸ì¶œ ì•ˆ ë¨)
# ============================================================================

EXTRACTION_PROMPT = """ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•´ì„œ ì‹œì¥ê²€ì¦ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

[ì¶”ì¶œ ê·œì¹™]
- í™•ì‹¤í•œ ì •ë³´ë§Œ ì¶”ì¶œ
- ì¶”ì •ì¸ ê²½ìš° "confidence": "low"ë¡œ í‘œì‹œ
- ì–¸ê¸‰ë˜ì§€ ì•Šì€ í•„ë“œëŠ” null

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
- idea_one_liner: ì•„ì´ë””ì–´ í•œ ë¬¸ì¥ ìš”ì•½ ë˜ëŠ” null
- target_customer: íƒ€ê¹ƒ ê³ ê° ë˜ëŠ” null
- problem_statement: í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œ ë˜ëŠ” null
- current_alternatives: í˜„ì¬ ëŒ€ì•ˆë“¤ ë˜ëŠ” null
- geo_market: KR/US/Global ë˜ëŠ” null
- business_type: B2B/B2C/B2B2C ë˜ëŠ” null
- confidence: ê° í•„ë“œë³„ high/medium/low
- raw_understanding: ì „ì²´ì ì¸ ì•„ì´ë””ì–´ ì´í•´ ìš”ì•½ (2~3ë¬¸ì¥)"""


# ============================================================================
# ë°ì´í„° í´ë˜ìŠ¤
# ============================================================================

@dataclass
class RefinerState:
    """ì¸í„°ë·°ì–´ì˜ ë‚´ë¶€ ìƒíƒœ"""
    raw_understanding: str = ""  # ììœ  í…ìŠ¤íŠ¸ ìš”ì•½
    hypotheses: Dict[str, Any] = field(default_factory=dict)  # ì¶”ì •í•œ í•„ë“œ
    confidence: Dict[str, str] = field(default_factory=dict)  # í™•ì‹  ìˆ˜ì¤€
    phase: str = "exploration"  # exploration / structuring
    turn_count: int = 0
    exploration_done: bool = False


@dataclass
class RefinerResult:
    """ì…ë ¥ êµ¬ì²´í™” ê²°ê³¼"""
    inputs: Dict[str, Any] = field(default_factory=dict)
    transcript: List[Dict[str, str]] = field(default_factory=list)
    confidence_flags: Dict[str, str] = field(default_factory=dict)
    is_confirmed: bool = False
    turns_used: int = 0


# ============================================================================
# í—¬í¼ í•¨ìˆ˜
# ============================================================================

def _get_llm(model_type: str = "fast") -> LLM:
    """LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    if model_type == "main":
        model = os.getenv("MAIN_LLM_MODEL", DEFAULT_MAIN_MODEL)
    else:
        model = os.getenv("REFINER_LLM_MODEL") or os.getenv("FAST_LLM_MODEL", DEFAULT_FAST_MODEL)
    return LLM(model=model)


def _extract_json_from_response(response: str) -> Optional[Dict[str, Any]]:
    """ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ"""
    if not response:
        return None
    
    # ```json ... ``` íŒ¨í„´
    match = re.search(r"```json\s*([\s\S]*?)\s*```", response, re.IGNORECASE)
    if match:
        try:
            return json.loads(match.group(1).strip())
        except json.JSONDecodeError:
            pass
    
    # ì „ì²´ê°€ JSON
    try:
        return json.loads(response.strip())
    except json.JSONDecodeError:
        pass
    
    # { ... } ì¶”ì¶œ
    first = response.find("{")
    last = response.rfind("}")
    if 0 <= first < last:
        try:
            return json.loads(response[first:last + 1])
        except json.JSONDecodeError:
            pass
    
    return None


def _format_understanding(state: RefinerState) -> str:
    """í˜„ì¬ ì´í•´ ìƒíƒœë¥¼ í¬ë§·íŒ…"""
    if not state.hypotheses:
        return "(ì•„ì§ ì´í•´í•œ ë‚´ìš© ì—†ìŒ)"
    
    lines = []
    field_labels = {
        "idea_one_liner": "ì•„ì´ë””ì–´",
        "target_customer": "íƒ€ê¹ƒ",
        "problem_statement": "ë¬¸ì œ",
        "current_alternatives": "í˜„ì¬ ëŒ€ì•ˆ",
        "geo_market": "ì‹œì¥",
        "business_type": "ë¹„ì¦ˆë‹ˆìŠ¤ ìœ í˜•",
    }
    
    for key, label in field_labels.items():
        value = state.hypotheses.get(key)
        if value:
            conf = state.confidence.get(key, "medium")
            marker = "âœ“" if conf == "high" else "?" if conf == "low" else "~"
            lines.append(f"[{marker}] {label}: {value}")
    
    if state.raw_understanding:
        lines.insert(0, f"ğŸ“ ìš”ì•½: {state.raw_understanding}\n")
    
    return "\n".join(lines) if lines else "(ì•„ì§ ì´í•´í•œ ë‚´ìš© ì—†ìŒ)"


def _get_unclear_parts(state: RefinerState) -> str:
    """ëª…í™•í•˜ì§€ ì•Šì€ ë¶€ë¶„ ëª©ë¡"""
    unclear = []
    
    for key in REQUIRED_FIELDS:
        value = state.hypotheses.get(key)
        conf = state.confidence.get(key, "low")
        
        if not value:
            unclear.append(f"- {key}: ì•„ì§ íŒŒì•… ì•ˆ ë¨")
        elif conf == "low":
            unclear.append(f"- {key}: ì¶”ì • ({value})")
    
    return "\n".join(unclear) if unclear else "ëª¨ë“  í•­ëª©ì´ ì¶©ë¶„íˆ íŒŒì•…ë¨"


def _should_transition_to_structuring(state: RefinerState) -> bool:
    """êµ¬ì¡°í™” ë‹¨ê³„ë¡œ ì „í™˜í• ì§€ íŒë‹¨"""
    # ìµœì†Œ 3í„´ ì´ìƒ + í•µì‹¬ 3ê°œ ì¤‘ 2ê°œ ì´ìƒ íŒŒì•…
    if state.turn_count < 3:
        return False
    
    core_fields = ["idea_one_liner", "target_customer", "problem_statement"]
    filled_count = sum(1 for f in core_fields if state.hypotheses.get(f))
    
    return filled_count >= 2


# ============================================================================
# ë©”ì¸ í´ë˜ìŠ¤
# ============================================================================

class InputRefiner:
    """ëŒ€í™”í˜• ì…ë ¥ êµ¬ì²´í™” - ì¸í„°ë·°ì–´ ìŠ¤íƒ€ì¼"""
    
    def __init__(self):
        self.llm = _get_llm("fast")
        self.llm_main = _get_llm("main")
        self.state = RefinerState()
        self.transcript: List[Dict[str, str]] = []
    
    def _generate_curiosity_angle(self) -> Optional[str]:
        """
        ëŠ¥ë™ì  í˜¸ê¸°ì‹¬ ì§ˆë¬¸ ìƒì„±
        - Exploration ë‹¨ê³„ì—ì„œ "ë‹¤ìŒì— ë¬´ì—‡ì´ ê°€ì¥ ê¶ê¸ˆí•œì§€"ë¥¼ LLMì—ê²Œ ë¬¼ì–´ë´„
        - ì´ ì˜ë„ë¥¼ system_promptì— ì£¼ì…í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìœ ë„
        """
        # ë„ˆë¬´ ì´ˆë°˜ì—ëŠ” í˜¸ê¸°ì‹¬ ì§ˆë¬¸ ë¶ˆí•„ìš”
        if not self.state.hypotheses and self.state.turn_count < 2:
            return None
        
        current_state = _format_understanding(self.state)
        messages = [
            {
                "role": "system",
                "content": f"{CURIOSITY_PROMPT}\n\n[í˜„ì¬ ì´í•´ ìƒíƒœ]\n{current_state}"
            },
            {
                "role": "user",
                "content": "í˜„ì¬ ì´í•´ ìƒíƒœë¥¼ ë³´ê³  ë‹¤ìŒìœ¼ë¡œ ê¶ê¸ˆí•œ ê´€ì ì„ ê³¨ë¼ì£¼ì„¸ìš”."
            }
        ]
        
        try:
            response = self.llm.call(messages=messages)
            parsed = _extract_json_from_response(response)
            
            if parsed and parsed.get("suggested_angle"):
                return parsed["suggested_angle"]
        except Exception:
            pass  # ì‹¤íŒ¨í•´ë„ ëŒ€í™” ì§„í–‰ì— ì˜í–¥ ì—†ìŒ
        
        return None
    
    def _should_extract_now(self, user_input: str) -> bool:
        """
        ì˜ë¯¸ ê¸°ë°˜ ì¶”ì¶œ íŠ¸ë¦¬ê±°
        - ì˜ë¯¸ ìˆëŠ” ë°œí™”ê°€ ë‚˜ì™”ì„ ë•Œë§Œ ì •ë³´ ì¶”ì¶œ
        - ë¶ˆí•„ìš”í•œ ì¶”ì¶œ ê°ì†Œ â†’ í’ˆì§ˆ â†‘, í† í° â†“
        """
        # ì‹ í˜¸ ë‹¨ì–´: í•µì‹¬ ì •ë³´ë¥¼ ë‹´ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ í‘œí˜„ë“¤
        signal_words = [
            "ê²°êµ­", "ê·¸ë˜ì„œ", "í•µì‹¬ì€", "ë¬¸ì œëŠ”", "ê°€ì¥", 
            "ì§„ì§œ", "ì¤‘ìš”í•œ ê±´", "ì•„ë§ˆ", "ëŠë‚Œìƒ", "ì‚¬ì‹¤",
            "ì™œëƒí•˜ë©´", "ë•Œë¬¸ì—", "ê·¸ë‹ˆê¹Œ", "ìš”ì•½í•˜ë©´",
            "ì§€ê¸ˆì€", "í˜„ì¬", "ëŒ€ì•ˆ", "ëŒ€ì‹ ", "ê²½ìŸ"
        ]
        
        if any(word in user_input for word in signal_words):
            return True
        
        # Phase ì „í™˜ ì§ì „ì€ ë¬´ì¡°ê±´ ì¶”ì¶œ
        if self.state.phase == "structuring":
            return True
        
        # ê¸´ ì‘ë‹µì€ ì˜ë¯¸ ìˆëŠ” ì •ë³´ í¬í•¨ ê°€ëŠ¥ì„± ë†’ìŒ
        if len(user_input) > 100:
            return True
        
        return False
    
    def _call_conversation_llm(self, user_message: str) -> str:
        """ëŒ€í™”ìš© LLM í˜¸ì¶œ (ìì—°ì–´ ì‘ë‹µ)"""
        
        # Phaseì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ì„ íƒ
        if self.state.phase == "exploration":
            system_prompt = EXPLORATION_PROMPT.format(
                current_understanding=_format_understanding(self.state),
                conversation_summary=self._get_conversation_summary(),
            )
            
            # ğŸ¯ ëŠ¥ë™ì  í˜¸ê¸°ì‹¬ ì§ˆë¬¸ ì£¼ì… (Exploration ë‹¨ê³„ì—ì„œë§Œ)
            curiosity_angle = self._generate_curiosity_angle()
            if curiosity_angle:
                system_prompt += f"\n\n[ë‹¤ìŒìœ¼ë¡œ ê¶ê¸ˆí•œ ê´€ì ]\n{curiosity_angle}"
        else:
            system_prompt = STRUCTURING_PROMPT.format(
                current_understanding=_format_understanding(self.state),
                unclear_parts=_get_unclear_parts(self.state),
                conversation_summary=self._get_conversation_summary(),
            )
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message},
        ]
        
        response = self.llm.call(messages=messages)
        
        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        self.transcript.append({"role": "user", "content": user_message})
        self.transcript.append({"role": "assistant", "content": response})
        
        return response
    
    def _extract_info_from_conversation(self) -> None:
        """ëŒ€í™”ì—ì„œ ì •ë³´ ì¶”ì¶œ (ë‚´ë¶€ìš©, ì‚¬ìš©ìì—ê²Œ ë…¸ì¶œ ì•ˆ ë¨)"""
        
        # ì „ì²´ ëŒ€í™”ë¥¼ í…ìŠ¤íŠ¸ë¡œ
        conversation_text = "\n".join([
            f"{'ì‚¬ìš©ì' if m['role'] == 'user' else 'ì‹œìŠ¤í…œ'}: {m['content']}"
            for m in self.transcript
        ])
        
        messages = [
            {"role": "system", "content": f"{EXTRACTION_PROMPT}\n\n[ëŒ€í™” ë‚´ìš©]\n{conversation_text}"},
            {"role": "user", "content": "ìœ„ ëŒ€í™”ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”."},
        ]
        
        response = self.llm_main.call(messages=messages)
        parsed = _extract_json_from_response(response)
        
        if parsed:
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            for key in REQUIRED_FIELDS:
                value = parsed.get(key)
                if value and value != "null":
                    self.state.hypotheses[key] = value
            
            # confidence ì—…ë°ì´íŠ¸
            conf = parsed.get("confidence", {})
            for key in REQUIRED_FIELDS:
                if key in conf:
                    self.state.confidence[key] = conf[key]
            
            # raw understanding
            if parsed.get("raw_understanding"):
                self.state.raw_understanding = parsed["raw_understanding"]
    
    def _get_conversation_summary(self) -> str:
        """ìµœê·¼ ëŒ€í™” ìš”ì•½ (ìµœëŒ€ 6ê°œ ë©”ì‹œì§€)"""
        recent = self.transcript[-6:]
        if not recent:
            return "(ëŒ€í™” ì‹œì‘)"
        
        return "\n".join([
            f"{'ì‚¬ìš©ì' if m['role'] == 'user' else 'ì‹œìŠ¤í…œ'}: {m['content'][:200]}..."
            if len(m['content']) > 200 else
            f"{'ì‚¬ìš©ì' if m['role'] == 'user' else 'ì‹œìŠ¤í…œ'}: {m['content']}"
            for m in recent
        ])
    
    def _finalize_inputs(self) -> Dict[str, Any]:
        """ìµœì¢… inputs ìƒì„± (ê¸°ë³¸ê°’ ì ìš©)"""
        inputs = {}
        
        for key in REQUIRED_FIELDS:
            value = self.state.hypotheses.get(key)
            if value:
                inputs[key] = value
            elif key in DEFAULT_VALUES:
                inputs[key] = DEFAULT_VALUES[key]
                self.state.confidence[key] = "assumed"
            else:
                inputs[key] = f"(ë¯¸ì •: {key})"
                self.state.confidence[key] = "missing"
        
        return inputs
    
    def _show_final_summary(self) -> str:
        """ìµœì¢… ìš”ì•½ ì¶œë ¥"""
        inputs = self._finalize_inputs()
        
        lines = [
            "\n" + "â•" * 60,
            "ğŸ“‹ ì‹œì¥ ê²€ì¦ INPUT ìµœì¢… í™•ì¸",
            "â•" * 60,
        ]
        
        field_labels = {
            "idea_one_liner": "ğŸ’¡ ì•„ì´ë””ì–´",
            "target_customer": "ğŸ‘¥ íƒ€ê¹ƒ ê³ ê°",
            "problem_statement": "ğŸ¯ í•´ê²°í•  ë¬¸ì œ",
            "current_alternatives": "ğŸ”„ í˜„ì¬ ëŒ€ì•ˆ",
            "geo_market": "ğŸŒ ì‹œì¥",
            "business_type": "ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ìœ í˜•",
        }
        
        assumed_fields = []
        
        for key in REQUIRED_FIELDS:
            label = field_labels.get(key, key)
            value = inputs.get(key, "")
            conf = self.state.confidence.get(key, "medium")
            
            if conf == "assumed":
                lines.append(f"{label}: {value} (ê¸°ë³¸ê°’)")
                assumed_fields.append(key)
            elif conf == "low":
                lines.append(f"{label}: {value} (ì¶”ì •)")
            else:
                lines.append(f"{label}: {value}")
        
        lines.append("â”€" * 60)
        
        if assumed_fields:
            lines.append(f"âš ï¸ ê¸°ë³¸ê°’ ì ìš©ëœ í•­ëª©: {', '.join(assumed_fields)}")
        
        lines.append("\nì´ëŒ€ë¡œ ì‹œì¥ ê²€ì¦ì„ ì‹œì‘í• ê¹Œìš”?")
        lines.append("'done' ë˜ëŠ” 'ì‹œì‘' â†’ ì§„í–‰ | ìˆ˜ì • ë‚´ìš© ì…ë ¥ â†’ ë°˜ì˜")
        lines.append("=" * 60)
        
        return "\n".join(lines)
    
    def refine(self, initial_idea: Optional[str] = None) -> RefinerResult:
        """ë©”ì¸ ëŒ€í™” ë£¨í”„"""
        
        print("\n" + "â•" * 60)
        print("ğŸ¯ Gap Foundry - ì•„ì´ë””ì–´ ì¸í„°ë·°")
        print("â•" * 60)
        print(f"ğŸ§  ëª¨ë¸: {self.llm.model}")
        print("â”€" * 60)
        print("ì•„ì´ë””ì–´ë¥¼ ììœ ë¡­ê²Œ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.")
        print("ì €ëŠ” ë¨¼ì € ì´í•´í•˜ë ¤ê³  ë…¸ë ¥í• ê²Œìš” ğŸ˜Š")
        print("")
        print("ëª…ë ¹ì–´: 'done'(ì™„ë£Œ) | 'status'(í˜„ì¬ ìƒíƒœ) | 'quit'(ì·¨ì†Œ)")
        print("â•" * 60 + "\n")
        
        # ì´ˆê¸° ì¸ì‚¬
        if initial_idea:
            print(f"ğŸ“ ì…ë ¥: {initial_idea}\n")
            response = self._call_conversation_llm(initial_idea)
            print(f"ğŸ¤– {response}\n")
            self.state.turn_count += 1
            
            # ì •ë³´ ì¶”ì¶œ (ë°±ê·¸ë¼ìš´ë“œ)
            self._extract_info_from_conversation()
        else:
            print("ğŸ¤– ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ì•„ì´ë””ì–´ë¥¼ ìƒê°í•˜ê³  ê³„ì‹ ê°€ìš”?")
            print("   í¸í•˜ê²Œ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”. íŒë‹¨í•˜ì§€ ì•Šê³  ë¨¼ì € ì´í•´í•˜ë ¤ê³  í• ê²Œìš”.\n")
        
        # ë©”ì¸ ëŒ€í™” ë£¨í”„ (max_turns ì—†ìŒ!)
        while True:
            try:
                user_input = input("ğŸ“ ì…ë ¥: ").strip()
            except (EOFError, KeyboardInterrupt):
                print("\n\nì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return RefinerResult(is_confirmed=False, turns_used=self.state.turn_count)
            
            if not user_input:
                continue
            
            cmd = user_input.lower().strip()
            
            # ëª…ë ¹ì–´ ì²˜ë¦¬
            if cmd in ["quit", "ì·¨ì†Œ", "exit", "q"]:
                print("\nì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return RefinerResult(is_confirmed=False, turns_used=self.state.turn_count)
            
            if cmd in ["status", "ìƒíƒœ"]:
                print("\n" + _format_understanding(self.state) + "\n")
                continue
            
            if cmd in ["done", "ì™„ë£Œ", "ì‹œì‘", "start", "ok", "yes", "ë„¤", "ã…‡", "í™•ì¸"]:
                # ìµœì¢… í™•ì¸ ë‹¨ê³„
                if self.state.phase == "exploration":
                    # ì•„ì§ explorationì´ë©´ â†’ structuringìœ¼ë¡œ ì „í™˜
                    self.state.phase = "structuring"
                    self._extract_info_from_conversation()
                    print(self._show_final_summary())
                    continue
                else:
                    # ì´ë¯¸ structuringì´ë©´ â†’ ì™„ë£Œ
                    break
            
            # ëŒ€í™” ì§„í–‰
            self.state.turn_count += 1
            
            # Structuring phaseì—ì„œ ìˆ˜ì • ì…ë ¥ ì‹œ â†’ ë°˜ì˜ í›„ ìµœì¢… í™”ë©´ ë‹¤ì‹œ í‘œì‹œ
            if self.state.phase == "structuring":
                # ìˆ˜ì • ë‚´ìš©ì„ ëŒ€í™”ì— ì¶”ê°€í•˜ê³  ì¬ì¶”ì¶œ
                self.transcript.append({"role": "user", "content": user_input})
                self._extract_info_from_conversation()
                print("\nâœ… ìˆ˜ì • ë‚´ìš©ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
                print(self._show_final_summary())
                continue  # AI ëŒ€í™” ì‘ë‹µ ê±´ë„ˆë›°ê¸°
            
            # Phase ì „í™˜ ì²´í¬ (exploration â†’ structuring ì œì•ˆ)
            if self.state.phase == "exploration" and _should_transition_to_structuring(self.state):
                self._extract_info_from_conversation()
                
                # ìì—°ìŠ¤ëŸ½ê²Œ êµ¬ì¡°í™” ì œì•ˆ (ì´ í„´ì—ì„œëŠ” AI ì‘ë‹µ ê±´ë„ˆë›°ê¸°)
                if not self.state.exploration_done:
                    self.state.exploration_done = True
                    print("\n" + "â”€" * 50)
                    print("âœ… ì•„ì´ë””ì–´ê°€ ì¶©ë¶„íˆ ì´í•´ëì–´ìš”!")
                    print("â”€" * 50)
                    print("\në‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:")
                    print("  ğŸ‘‰ 'done' ë˜ëŠ” 'ì‹œì‘' â†’ ì •ë¦¬ëœ ë‚´ìš© í™•ì¸ í›„ ì‹œì¥ ê²€ì¦ ì‹œì‘")
                    print("  ğŸ‘‰ ê³„ì† ì…ë ¥ â†’ ë” ì´ì•¼ê¸°í•˜ê³  ì‹¶ìœ¼ë©´ ììœ ë¡­ê²Œ\n")
                    continue  # AI ì‘ë‹µ ê±´ë„ˆë›°ê¸°
            
            # ëŒ€í™” ì‘ë‹µ (exploration phaseì—ì„œë§Œ)
            response = self._call_conversation_llm(user_input)
            print(f"\nğŸ¤– {response}\n")
            
            # ğŸ¯ ì˜ë¯¸ ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ (í•µì‹¬ ë°œí™”ê°€ ìˆì„ ë•Œë§Œ)
            if self._should_extract_now(user_input):
                self._extract_info_from_conversation()
        
        # ìµœì¢… inputs ìƒì„±
        final_inputs = self._finalize_inputs()
        
        # confidence flags ê³„ì‚°
        confidence_flags = {}
        for f in REQUIRED_FIELDS:
            conf = self.state.confidence.get(f, "medium")
            if conf == "assumed":
                confidence_flags[f] = "assumed"
            elif conf == "low":
                confidence_flags[f] = "low"
            elif not self.state.hypotheses.get(f):
                confidence_flags[f] = "missing"
            else:
                confidence_flags[f] = "ok"
        
        return RefinerResult(
            inputs=final_inputs,
            transcript=self.transcript,
            confidence_flags=confidence_flags,
            is_confirmed=True,
            turns_used=self.state.turn_count,
        )


# ============================================================================
# ê³µê°œ ì¸í„°í˜ì´ìŠ¤
# ============================================================================

def refine_inputs(
    initial_idea: Optional[str] = None,
) -> Dict[str, Any]:
    """
    ëŒ€í™”í˜•ìœ¼ë¡œ ì…ë ¥ì„ êµ¬ì²´í™”í•˜ëŠ” í—¬í¼ í•¨ìˆ˜.
    
    Returns:
        dict with keys:
        - inputs
        - transcript
        - confidence_flags
        - is_confirmed
        - turns_used
        
        ì·¨ì†Œ ì‹œ ë¹ˆ dict ë°˜í™˜
    """
    refiner = InputRefiner()
    result = refiner.refine(initial_idea)
    
    if not result.is_confirmed:
        return {}
    
    return {
        "inputs": result.inputs,
        "transcript": result.transcript,
        "confidence_flags": result.confidence_flags,
        "is_confirmed": result.is_confirmed,
        "turns_used": result.turns_used,
    }


# ============================================================================
# ì§ì ‘ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    result = refine_inputs()
    
    if result:
        print("\n" + "â•" * 60)
        print("âœ… ìµœì¢… ê²°ê³¼")
        print("â•" * 60)
        print(f"í„´ ìˆ˜: {result['turns_used']}")
        print(f"confidence: {result['confidence_flags']}")
        print(f"\ninputs:\n{json.dumps(result['inputs'], ensure_ascii=False, indent=2)}")
